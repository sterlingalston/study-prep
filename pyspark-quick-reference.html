<!DOCTYPE html>
<!-- saved from url=(0069)https://www.sparkplayground.com/pyspark-cheat-sheet#selecting-columns -->
<html lang="en" data-theme="nord" class="__className_d65c78" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style>.Õº1.cm-focused {outline: 1px dotted #212121;}
.Õº1 {position: relative !important; box-sizing: border-box; display: flex !important; flex-direction: column;}
.Õº1 .cm-scroller {display: flex !important; align-items: flex-start !important; font-family: monospace; line-height: 1.4; height: 100%; overflow-x: auto; position: relative; z-index: 0; overflow-anchor: none;}
.Õº1 .cm-content[contenteditable=true] {-webkit-user-modify: read-write-plaintext-only;}
.Õº1 .cm-content {margin: 0; flex-grow: 2; flex-shrink: 0; display: block; white-space: pre; word-wrap: normal; box-sizing: border-box; min-height: 100%; padding: 4px 0; outline: none;}
.Õº1 .cm-lineWrapping {white-space: pre-wrap; white-space: break-spaces; word-break: break-word; overflow-wrap: anywhere; flex-shrink: 1;}
.Õº2 .cm-content {caret-color: black;}
.Õº3 .cm-content {caret-color: white;}
.Õº1 .cm-line {display: block; padding: 0 2px 0 6px;}
.Õº1 .cm-layer > * {position: absolute;}
.Õº1 .cm-layer {position: absolute; left: 0; top: 0; contain: size style;}
.Õº2 .cm-selectionBackground {background: #d9d9d9;}
.Õº3 .cm-selectionBackground {background: #222;}
.Õº2.cm-focused > .cm-scroller > .cm-selectionLayer .cm-selectionBackground {background: #d7d4f0;}
.Õº3.cm-focused > .cm-scroller > .cm-selectionLayer .cm-selectionBackground {background: #233;}
.Õº1 .cm-cursorLayer {pointer-events: none;}
.Õº1.cm-focused > .cm-scroller > .cm-cursorLayer {animation: steps(1) cm-blink 1.2s infinite;}
@keyframes cm-blink {50% {opacity: 0;}}
@keyframes cm-blink2 {50% {opacity: 0;}}
.Õº1 .cm-cursor, .Õº1 .cm-dropCursor {border-left: 1.2px solid black; margin-left: -0.6px; pointer-events: none;}
.Õº1 .cm-cursor {display: none;}
.Õº3 .cm-cursor {border-left-color: #ddd;}
.Õº1 .cm-dropCursor {position: absolute;}
.Õº1.cm-focused > .cm-scroller > .cm-cursorLayer .cm-cursor {display: block;}
.Õº1 .cm-iso {unicode-bidi: isolate;}
.Õº1 .cm-announced {position: fixed; top: -10000px;}
@media print {.Õº1 .cm-announced {display: none;}}
.Õº2 .cm-activeLine {background-color: #cceeff44;}
.Õº3 .cm-activeLine {background-color: #99eeff33;}
.Õº2 .cm-specialChar {color: red;}
.Õº3 .cm-specialChar {color: #f78;}
.Õº1 .cm-gutters {flex-shrink: 0; display: flex; height: 100%; box-sizing: border-box; inset-inline-start: 0; z-index: 200;}
.Õº2 .cm-gutters {background-color: #f5f5f5; color: #6c6c6c; border-right: 1px solid #ddd;}
.Õº3 .cm-gutters {background-color: #333338; color: #ccc;}
.Õº1 .cm-gutter {display: flex !important; flex-direction: column; flex-shrink: 0; box-sizing: border-box; min-height: 100%; overflow: hidden;}
.Õº1 .cm-gutterElement {box-sizing: border-box;}
.Õº1 .cm-lineNumbers .cm-gutterElement {padding: 0 3px 0 5px; min-width: 20px; text-align: right; white-space: nowrap;}
.Õº2 .cm-activeLineGutter {background-color: #e2f2ff;}
.Õº3 .cm-activeLineGutter {background-color: #222227;}
.Õº1 .cm-panels {box-sizing: border-box; position: sticky; left: 0; right: 0; z-index: 300;}
.Õº2 .cm-panels {background-color: #f5f5f5; color: black;}
.Õº2 .cm-panels-top {border-bottom: 1px solid #ddd;}
.Õº2 .cm-panels-bottom {border-top: 1px solid #ddd;}
.Õº3 .cm-panels {background-color: #333338; color: white;}
.Õº1 .cm-tab {display: inline-block; overflow: hidden; vertical-align: bottom;}
.Õº1 .cm-widgetBuffer {vertical-align: text-top; height: 1em; width: 0; display: inline;}
.Õº1 .cm-placeholder {color: #888; display: inline-block; vertical-align: top;}
.Õº1 .cm-highlightSpace {background-image: radial-gradient(circle at 50% 55%, #aaa 20%, transparent 5%); background-position: center;}
.Õº1 .cm-highlightTab {background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="200" height="20"><path stroke="%23888" stroke-width="1" fill="none" d="M1 10H196L190 5M190 15L196 10M197 4L197 16"/></svg>'); background-size: auto 100%; background-position: right 90%; background-repeat: no-repeat;}
.Õº1 .cm-trailingSpace {background-color: #ff332255;}
.Õº1 .cm-button {vertical-align: middle; color: inherit; font-size: 70%; padding: .2em 1em; border-radius: 1px;}
.Õº2 .cm-button:active {background-image: linear-gradient(#b4b4b4, #d0d3d6);}
.Õº2 .cm-button {background-image: linear-gradient(#eff1f5, #d9d9df); border: 1px solid #888;}
.Õº3 .cm-button:active {background-image: linear-gradient(#111, #333);}
.Õº3 .cm-button {background-image: linear-gradient(#393939, #111); border: 1px solid #888;}
.Õº1 .cm-textfield {vertical-align: middle; color: inherit; font-size: 70%; border: 1px solid silver; padding: .2em .5em;}
.Õº2 .cm-textfield {background-color: white;}
.Õº3 .cm-textfield {border: 1px solid #555; background-color: inherit;}
.Õº1 .cm-selectionMatch {background-color: #99ff7780;}
.Õº1 .cm-searchMatch .cm-selectionMatch {background-color: transparent;}
.Õº1 .cm-tooltip.cm-tooltip-autocomplete > ul > li, .Õº1 .cm-tooltip.cm-tooltip-autocomplete > ul > completion-section {padding: 1px 3px; line-height: 1.2;}
.Õº1 .cm-tooltip.cm-tooltip-autocomplete > ul > li {overflow-x: hidden; text-overflow: ellipsis; cursor: pointer;}
.Õº1 .cm-tooltip.cm-tooltip-autocomplete > ul > completion-section {display: list-item; border-bottom: 1px solid silver; padding-left: 0.5em; opacity: 0.7;}
.Õº1 .cm-tooltip.cm-tooltip-autocomplete > ul {font-family: monospace; white-space: nowrap; overflow: hidden auto; max-width: 700px; max-width: min(700px, 95vw); min-width: 250px; max-height: 10em; height: 100%; list-style: none; margin: 0; padding: 0;}
.Õº2 .cm-tooltip-autocomplete ul li[aria-selected] {background: #17c; color: white;}
.Õº2 .cm-tooltip-autocomplete-disabled ul li[aria-selected] {background: #777;}
.Õº3 .cm-tooltip-autocomplete ul li[aria-selected] {background: #347; color: white;}
.Õº3 .cm-tooltip-autocomplete-disabled ul li[aria-selected] {background: #444;}
.Õº1 .cm-completionListIncompleteTop:before, .Õº1 .cm-completionListIncompleteBottom:after {content: "¬∑¬∑¬∑"; opacity: 0.5; display: block; text-align: center;}
.Õº1 .cm-tooltip.cm-completionInfo {position: absolute; padding: 3px 9px; width: max-content; max-width: 400px; box-sizing: border-box; white-space: pre-line;}
.Õº1 .cm-completionInfo.cm-completionInfo-left {right: 100%;}
.Õº1 .cm-completionInfo.cm-completionInfo-right {left: 100%;}
.Õº1 .cm-completionInfo.cm-completionInfo-left-narrow {right: 30px;}
.Õº1 .cm-completionInfo.cm-completionInfo-right-narrow {left: 30px;}
.Õº2 .cm-snippetField {background-color: #00000022;}
.Õº3 .cm-snippetField {background-color: #ffffff22;}
.Õº1 .cm-snippetFieldPosition {vertical-align: text-top; width: 0; height: 1.15em; display: inline-block; margin: 0 -0.7px -.7em; border-left: 1.4px dotted #888;}
.Õº1 .cm-completionMatchedText {text-decoration: underline;}
.Õº1 .cm-completionDetail {margin-left: 0.5em; font-style: italic;}
.Õº1 .cm-completionIcon {font-size: 90%; width: .8em; display: inline-block; text-align: center; padding-right: .6em; opacity: 0.6; box-sizing: content-box;}
.Õº1 .cm-completionIcon-function:after, .Õº1 .cm-completionIcon-method:after {content: '∆í';}
.Õº1 .cm-completionIcon-class:after {content: '‚óã';}
.Õº1 .cm-completionIcon-interface:after {content: '‚óå';}
.Õº1 .cm-completionIcon-variable:after {content: 'ùë•';}
.Õº1 .cm-completionIcon-constant:after {content: 'ùê∂';}
.Õº1 .cm-completionIcon-type:after {content: 'ùë°';}
.Õº1 .cm-completionIcon-enum:after {content: '‚à™';}
.Õº1 .cm-completionIcon-property:after {content: '‚ñ°';}
.Õº1 .cm-completionIcon-keyword:after {content: 'üîëÔ∏é';}
.Õº1 .cm-completionIcon-namespace:after {content: '‚ñ¢';}
.Õº1 .cm-completionIcon-text:after {content: 'abc'; font-size: 50%; vertical-align: middle;}
.Õº1 .cm-tooltip {z-index: 500; box-sizing: border-box;}
.Õº2 .cm-tooltip {border: 1px solid #bbb; background-color: #f5f5f5;}
.Õº2 .cm-tooltip-section:not(:first-child) {border-top: 1px solid #bbb;}
.Õº3 .cm-tooltip {background-color: #333338; color: white;}
.Õº1 .cm-tooltip-arrow:before, .Õº1 .cm-tooltip-arrow:after {content: ''; position: absolute; width: 0; height: 0; border-left: 7px solid transparent; border-right: 7px solid transparent;}
.Õº1 .cm-tooltip-above .cm-tooltip-arrow:before {border-top: 7px solid #bbb;}
.Õº1 .cm-tooltip-above .cm-tooltip-arrow:after {border-top: 7px solid #f5f5f5; bottom: 1px;}
.Õº1 .cm-tooltip-above .cm-tooltip-arrow {bottom: -7px;}
.Õº1 .cm-tooltip-below .cm-tooltip-arrow:before {border-bottom: 7px solid #bbb;}
.Õº1 .cm-tooltip-below .cm-tooltip-arrow:after {border-bottom: 7px solid #f5f5f5; top: 1px;}
.Õº1 .cm-tooltip-below .cm-tooltip-arrow {top: -7px;}
.Õº1 .cm-tooltip-arrow {height: 7px; width: 14px; position: absolute; z-index: -1; overflow: hidden;}
.Õº3 .cm-tooltip .cm-tooltip-arrow:before {border-top-color: #333338; border-bottom-color: #333338;}
.Õº3 .cm-tooltip .cm-tooltip-arrow:after {border-top-color: transparent; border-bottom-color: transparent;}
.Õº1.cm-focused .cm-matchingBracket {background-color: #328c8252;}
.Õº1.cm-focused .cm-nonmatchingBracket {background-color: #bb555544;}
.Õº1 .cm-foldPlaceholder {background-color: #eee; border: 1px solid #ddd; color: #888; border-radius: .2em; margin: 0 1px; padding: 0 1px; cursor: pointer;}
.Õº1 .cm-foldGutter span {padding: 0 1px; cursor: pointer;}
.Õº15 {background-color: #fff;}
.Õº5 {color: #404740;}
.Õº6 {text-decoration: underline;}
.Õº7 {text-decoration: underline; font-weight: bold;}
.Õº8 {font-style: italic;}
.Õº9 {font-weight: bold;}
.Õºa {text-decoration: line-through;}
.Õºb {color: #708;}
.Õºc {color: #219;}
.Õºd {color: #164;}
.Õºe {color: #a11;}
.Õºf {color: #e40;}
.Õºg {color: #00f;}
.Õºh {color: #30a;}
.Õºi {color: #085;}
.Õºj {color: #167;}
.Õºk {color: #256;}
.Õºl {color: #00c;}
.Õºm {color: #940;}
.Õºn {color: #f00;}
.Õº1a {height: 40vh;}
.Õº1a .cm-scroller {height: 100% !important;}
.Õº18 {height: 40vh;}
.Õº18 .cm-scroller {height: 100% !important;}
.Õº4 .cm-line ::selection, .Õº4 .cm-line::selection {background-color: transparent !important;}
.Õº4 .cm-line {caret-color: transparent !important;}
.Õº4 .cm-content :focus::selection, .Õº4 .cm-content :focus ::selection {background-color: Highlight !important;}
.Õº4 .cm-content :focus {caret-color: initial !important;}
.Õº4 .cm-content {caret-color: transparent !important;}
</style><link rel="stylesheet" href="./PySpark Cheat Sheet - Quick Reference Guide_files/bb98467c3ae26f97.css" data-precedence="next"><link rel="stylesheet" href="./PySpark Cheat Sheet - Quick Reference Guide_files/dcee3e6b25e69456.css" data-precedence="next"><link rel="stylesheet" href="./PySpark Cheat Sheet - Quick Reference Guide_files/6b786b77af9d8e90.css" data-precedence="next"><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/52774a7f-26738e0021f6aee7.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/fd9d1056-86d517a5da58b0b6.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/4596-3bdea44ee4d5cc00.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/main-app-70c641da5736cc72.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/363642f4-7c53c26b3cae50a2.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/7213-38a144ea1b950207.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/5737-934819be758c71d4.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/372-8a9ef7cb5cbd022d.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/7671-eda41bc69b0cfac7.js.download" async=""></script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/polyfills-42372ed130431b0a.js.download" nomodule=""></script><script id="simplify-jobs-page-script" src="chrome-extension://pbanhockgagggenencehbnadejlgchfc/js/pageScript.bundle.js"></script><style id="_goober"> @keyframes go2264125279{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go3020080000{from{transform:scale(0);opacity:0;}to{transform:scale(1);opacity:1;}}@keyframes go463499852{from{transform:scale(0) rotate(90deg);opacity:0;}to{transform:scale(1) rotate(90deg);opacity:1;}}@keyframes go1268368563{from{transform:rotate(0deg);}to{transform:rotate(360deg);}}@keyframes go1310225428{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go651618207{0%{height:0;width:0;opacity:0;}40%{height:0;width:6px;opacity:1;}100%{opacity:1;height:10px;}}@keyframes go901347462{from{transform:scale(0.6);opacity:0.4;}to{transform:scale(1);opacity:1;}}.go4109123758{z-index:9999;}.go4109123758 > *{pointer-events:auto;}</style><style id="react-tooltip-core-styles" type="text/css">:root{--rt-color-white:#fff;--rt-color-dark:#222;--rt-color-success:#8dc572;--rt-color-error:#be6464;--rt-color-warning:#f0ad4e;--rt-color-info:#337ab7;--rt-opacity:0.9;--rt-transition-show-delay:0.15s;--rt-transition-closing-delay:0.15s}.core-styles-module_tooltip__3vRRp{position:absolute;top:0;left:0;pointer-events:none;opacity:0;will-change:opacity}.core-styles-module_fixed__pcSol{position:fixed}.core-styles-module_arrow__cvMwQ{position:absolute;background:inherit}.core-styles-module_noArrow__xock6{display:none}.core-styles-module_clickable__ZuTTB{pointer-events:auto}.core-styles-module_show__Nt9eE{opacity:var(--rt-opacity);transition:opacity var(--rt-transition-show-delay)ease-out}.core-styles-module_closing__sGnxF{opacity:0;transition:opacity var(--rt-transition-closing-delay)ease-in}</style><style id="react-tooltip-base-styles" type="text/css">
.styles-module_tooltip__mnnfp{padding:8px 16px;border-radius:3px;font-size:90%;width:max-content}.styles-module_arrow__K0L3T{width:8px;height:8px}[class*='react-tooltip__place-top']>.styles-module_arrow__K0L3T{transform:rotate(45deg)}[class*='react-tooltip__place-right']>.styles-module_arrow__K0L3T{transform:rotate(135deg)}[class*='react-tooltip__place-bottom']>.styles-module_arrow__K0L3T{transform:rotate(225deg)}[class*='react-tooltip__place-left']>.styles-module_arrow__K0L3T{transform:rotate(315deg)}.styles-module_dark__xNqje{background:var(--rt-color-dark);color:var(--rt-color-white)}.styles-module_light__Z6W-X{background-color:var(--rt-color-white);color:var(--rt-color-dark)}.styles-module_success__A2AKt{background-color:var(--rt-color-success);color:var(--rt-color-white)}.styles-module_warning__SCK0X{background-color:var(--rt-color-warning);color:var(--rt-color-white)}.styles-module_error__JvumD{background-color:var(--rt-color-error);color:var(--rt-color-white)}.styles-module_info__BWdHW{background-color:var(--rt-color-info);color:var(--rt-color-white)}</style><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="theme-color" content="#5E81AC"><title>PySpark Cheat Sheet - Quick Reference Guide</title><meta name="description" content="Quick reference for essential PySpark functions with examples. Learn data transformations, string manipulation, and more in the cheat sheet."><meta name="application-name" content="Spark Playground"><meta name="keywords" content="Spark Playground"><meta name="impact-site-verification" content="a8d6651a-7154-4e28-aa0c-d78ea5ccd988"><link rel="canonical" href="https://www.sparkplayground.com/pyspark-cheat-sheet"><meta property="og:title" content="Spark Playground"><meta property="og:description" content="Platform to learn, practice, and solve PySpark interview questions to land your next DE role."><meta property="og:url" content="https://sparkplayground.com"><meta property="og:site_name" content="Spark Playground"><meta property="og:locale" content="en_US"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image" content="https://www.sparkplayground.com/opengraph-image.png?d6406e9a3aa550ce"><meta property="og:type" content="website"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@rizal_rovins"><meta name="twitter:title" content="Spark Playground"><meta name="twitter:description" content="Platform to learn, practice, and solve PySpark interview questions to land your next DE role."><meta name="twitter:image:type" content="image/png"><meta name="twitter:image:width" content="1200"><meta name="twitter:image:height" content="630"><meta name="twitter:image" content="https://www.sparkplayground.com/twitter-image.png?d6406e9a3aa550ce"><link rel="icon" href="https://www.sparkplayground.com/favicon.ico" type="image/x-icon" sizes="48x48"><link rel="icon" href="https://www.sparkplayground.com/icon.png?8e0bf7a07d09542a" type="image/png" sizes="1200x1200"><link rel="apple-touch-icon" href="https://www.sparkplayground.com/apple-icon.png?52e4779274dcf9c5" type="image/png" sizes="180x180"><meta name="next-size-adjust"><style></style></head><body style=""><style>#nprogress{pointer-events:none}#nprogress .bar{background:#446dff;position:fixed;z-index:1600;top: 0;left:0;width:100%;height:3px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #446dff,0 0 5px #446dff;opacity:1;-webkit-transform:rotate(3deg) translate(0px,-4px);-ms-transform:rotate(3deg) translate(0px,-4px);transform:rotate(3deg) translate(0px,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1600;top: 15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:2px solid transparent;border-top-color:#446dff;border-left-color:#446dff;border-radius:50%;-webkit-animation:nprogress-spinner 400ms linear infinite;animation:nprogress-spinner 400ms linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .bar,.nprogress-custom-parent #nprogress .spinner{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0deg)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}</style><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/webpack-41ff1f12559a108f.js.download" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/b957ea75a84b6ea7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/media/eafabf029ad39a43-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/css/bb98467c3ae26f97.css\",\"style\"]\n5:HL[\"/_next/static/css/dcee3e6b25e69456.css\",\"style\"]\n6:HL[\"/_next/static/css/6b786b77af9d8e90.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"7:I[14360,[],\"\"]\n9:I[20576,[],\"ClientPageRoot\"]\na:I[5113,[\"6401\",\"static/chunks/363642f4-7c53c26b3cae50a2.js\",\"7213\",\"static/chunks/7213-38a144ea1b950207.js\",\"5737\",\"static/chunks/5737-934819be758c71d4.js\",\"6243\",\"static/chunks/6243-0076d0ceb5786f67.js\",\"372\",\"static/chunks/372-8a9ef7cb5cbd022d.js\",\"996\",\"static/chunks/996-c9cb07d59ee6f07a.js\",\"7671\",\"static/chunks/7671-eda41bc69b0cfac7.js\",\"8112\",\"static/chunks/8112-bdcc450e60d68e5b.js\",\"1070\",\"static/chunks/1070-f7abfffe2cfe264e.js\",\"5178\",\"static/chunks/5178-23e027c5701a6e04.js\",\"2753\",\"static/chunks/2753-6390a20fc2499868.js\",\"5113\",\"static/chunks/5113-b0f8d068d3330da7.js\",\"1550\",\"static/chunks/app/pyspark-online-compiler/layout-06a6c40c7f822345.js\"],\"default\",1]\nb:I[69257,[],\"\"]\nc:I[14857,[],\"\"]\ne:I[87512,[\"5737\",\"static/chunks/5737-934819be758c71d4.js\",\"7699\",\"static/chunks/7699-e3ed48b044ef6c5c.js\",\"5629\",\"static/chunks/5629-56f5639c009af1c9.js\",\"3185\",\"static/chunks/app/layout-3fb8527a12c0289f.js\"],\"\"]\nf:I[39294,[\"5737\",\"static/chunks/5737-934819be758c71d4.js\",\"7699\",\"static/chunks/7699-e3ed48b044ef6c5c.js\",\"5629\",\"static/chunks/5629-56f5639c009af1c9.js\",\"3185\",\"static/chunks/app/layout-3fb8527a12c0289f.js\"],\"default\"]\n10:I[53074,[\"7213\",\"static/chunks/7213-38a144ea1b950207.js\",\"5963\",\"static/chunks/5963-624b61da615af144.js\",\"7601\",\"static/chunks/app/error-c33a5d7a765a6abf.js\"],\"default\"]\n17:I[77213,[\"7213\",\"static/chunks/7213-38a144ea1b950207.js\",\"5737\",\"static/chunks/5737-934819be758c71d4.js\",\"6243\",\"static/chunks/6243-0076d0ceb5786f67.js\",\"372\",\"static/chunks/372-8a9ef7cb5cbd022d.js\",\"996\",\"static/chunks/996-c9cb07d59ee6f07a.js\",\"3202\",\"static/chunks/3202-5a4a7e68363416a7.js\",\"6898\",\"static/chunks/6898-7e4c3dd49cedf063.js\",\"2753\",\"static/chunks/2753-6390a20fc2499868.js\",\"1931\",\"static/chunks/app/page-764ff1f50c755f3b.js\"],\"\"]\n18:I[98824,[\"7213\",\"static/chunks/7213-38a144ea1b950207.js\",\"5963\",\"static/chunks/5963-624b61da615af144.js\",\"9160\",\"static/chunks/app/not-found-f40f8a99154b194f.js\"],\"default\"]\n19:I[40779,[\"5737\",\"static/chunks/5737-934819be758c71d"])</script><script>self.__next_f.push([1,"4.js\",\"7699\",\"static/chunks/7699-e3ed48b044ef6c5c.js\",\"5629\",\"static/chunks/5629-56f5639c009af1c9.js\",\"3185\",\"static/chunks/app/layout-3fb8527a12c0289f.js\"],\"GoogleAnalytics\"]\n1b:I[50676,[\"6470\",\"static/chunks/app/global-error-5e7009e1740a8816.js\"],\"default\"]\nd:{}\n11:T627,M697.636 545.355c-4.711-5.95-6.637-7.343-11.284-13.347q-56.765-73.417-106.708-151.793-33.924-53.23-64.483-108.504-14.549-26.278-28.3-52.969-10.67-20.695-20.864-41.638a841.984 841.984 0 0 1-5.711-12.009c-4.428-9.442-8.774-18.93-13.44-28.244-5.317-10.616-11.789-21.745-21.552-28.877a29.405 29.405 0 0 0-15.319-5.895c-7.948-.513-15.282 2.769-22.176 6.353-50.438 26.301-97.659 59.276-140.37 96.798A730.778 730.778 0 0 0 133.39 331.82c-1.009 1.44-3.393.064-2.375-1.384q6.01-8.498 12.257-16.813a734.817 734.817 0 0 1 187.6-174.986q18.248-11.825 37.182-22.542c6.362-3.603 12.752-7.16 19.251-10.497 6.372-3.272 13.137-6.215 20.416-6.325 24.77-.385 37.595 27.667 46.405 46.542q4.153 8.911 8.406 17.767 16.075 33.62 33.388 66.628 10.684 20.379 21.837 40.52 34.707 62.717 73.778 122.896c34.506 53.143 68.737 100.089 108.046 149.785 1.082 1.375-.852 3.337-1.944 1.943ZM244.982 191.378c-1.44-1.604-2.87-3.209-4.318-4.813-11.422-12.632-23.679-25.118-39.364-32.36a57.11 57.11 0 0 0-23.927-5.547c-8.562.028-16.932 2.274-24.843 5.418-3.74 1.494-7.399 3.19-11.001 4.996-4.116 2.072-8.16 4.281-12.183 6.51q-11.332 6.27-22.369 13.09-21.96 13.572-42.545 29.216-10.671 8.113-20.902 16.758-9.516 8.03-18.646 16.492c-1.302 1.201-3.245-.742-1.944-1.943a441.255 441.255 0 0 1 4.85-4.446q6.875-6.216 13.971-12.193 12.94-10.918 26.549-20.993 21.162-15.676 43.782-29.226 11.304-6.765 22.919-12.962a198.735 198.735 0 0 1 7.095-3.621 113.116 113.116 0 0 1 16.868-6.867 60.006 60.006 0 0 1 25.476-2.502 66.327 66.327 0 0 1 23.505 8.131c15.401 8.608 27.346 21.92 38.97 34.91 1.174 1.32-.76 3.272-1.943 1.952Z12:T43d,M851.011 92.728a.982.982 0 0 1-.302-.047C586.303 9.063 353.265 19.998 204.33 43.895a1294.017 1294.017 0 0 0-60.403 11.161 1196.246 1196.246 0 0 0-15.597 3.378 1023.104 1023.104 0 0 0-18.532 4."])</script><script>self.__next_f.push([1,"306q-3.873.917-7.595 1.849a972.21 972.21 0 0 0-11.66 2.957 930.173 930.173 0 0 0-13.797 3.671.442.442 0 0 1-.051.015v.001a926.363 926.363 0 0 0-15.323 4.325c-2.698.78-5.304 1.548-7.8 2.307-.278.077-.525.151-.776.227l-.536.164c-.31.094-.617.187-.924.275l-.02.006h.001l-.811.253c-.968.293-1.912.579-2.841.864C23.119 87.22 9.626 92.604 9.493 92.656a1 1 0 1 1-.744-1.856c.134-.053 13.693-5.463 38.327-13.058.932-.286 1.88-.572 2.85-.866l.754-.235c.026-.01.051-.017.078-.025.305-.087.61-.18.92-.273l.536-.164c.268-.08.532-.16.802-.235a593.8 593.8 0 0 1 7.797-2.307 932.235 932.235 0 0 1 15.334-4.328c.017-.006.033-.01.05-.014v-.001a941.379 941.379 0 0 1 13.844-3.685 993.766 993.766 0 0 1 11.68-2.962q3.738-.93 7.61-1.852a1026.011 1026.011 0 0 1 18.563-4.313c5.299-1.183 10.555-2.322 15.622-3.383a1295.424 1295.424 0 0 1 60.497-11.178c149.149-23.932 382.52-34.884 647.299 48.854a1 1 0 0 1-.3 1.953Z13:Ta15,"])</script><script>self.__next_f.push([1,"M262.989 419.84a6.73 6.73 0 0 0-1.7-2.67 6.43 6.43 0 0 0-.92-.71c-2.61-1.74-6.51-2.13-8.99 0a5.81 5.81 0 0 0-.69.71q-1.11 1.365-2.28 2.67a88.226 88.226 0 0 1-3.96 4.24c-.39.38-.78.77-1.18 1.15-.23.23-.46.45-.69.67-.88.84-1.78 1.65-2.69 2.45-.48.43-.96.85-1.45 1.26-.73.61-1.46 1.22-2.2 1.81-.07.05-.14.1-.21.16-.02.01-.03.03-.05.04-.01 0-.02 0-.03.02a.179.179 0 0 0-.07.05c-.22.15-.37.25-.48.34.04-.02.08-.05.12-.07-.18.14-.37.28-.55.42a92.853 92.853 0 0 1-5.37 3.69 99.21 99.21 0 0 1-14.22 7.55c-.33.13-.67.27-1.01.4a85.97 85.97 0 0 1-40.85 6.02q-2.13-.165-4.26-.45c-1.64-.24-3.27-.53-4.89-.86a97.932 97.932 0 0 1-18.02-5.44 118.652 118.652 0 0 1-20.66-12.12c-1-.71-2.01-1.42-3.02-2.11 1.15-2.82 2.28-5.64 3.38-8.48.55-1.37 1.08-2.74 1.6-4.12 4.09-10.63 7.93-21.36 11.61-32.13q5.58-16.365 10.53-32.92.51-1.68.99-3.36 2.595-8.745 4.98-17.53c.15-.57.31-1.13.45-1.7q.69-2.52 1.35-5.04c1-3.79-1.26-8.32-5.24-9.23a7.634 7.634 0 0 0-9.22 5.24c-.43 1.62-.86 3.23-1.3 4.85q-3.165 11.745-6.66 23.41l-1.02 3.36q-7.71 25.41-16.93 50.31-1.11 3.015-2.25 6.01c-.37.98-.74 1.96-1.12 2.94-.73 1.93-1.48 3.86-2.23 5.79-.43 1.13-.87 2.26-1.31 3.38-.29.71-.57 1.42-.85 2.12a41.81 41.81 0 0 0-8.81-2.12l-.48-.06a27.397 27.397 0 0 0-7.01.06 23.914 23.914 0 0 0-17.24 10.66c-4.77 7.51-4.71 18.25 1.98 24.63 6.89 6.57 17.32 6.52 25.43 2.41a28.351 28.351 0 0 0 10.52-9.86 50.57 50.57 0 0 0 2.74-4.65c.21.14.42.28.63.43.8.56 1.6 1.13 2.39 1.69a111.738 111.738 0 0 0 14.51 8.91 108.359 108.359 0 0 0 34.62 10.47c.27.03.53.07.8.1 1.33.17 2.67.3 4.01.41a103.782 103.782 0 0 0 55.58-11.36q2.175-1.125 4.31-2.36 3.315-1.92 6.48-4.08c1.15-.78 2.27-1.57 3.38-2.4a101.042 101.042 0 0 0 13.51-11.95q2.355-2.475 4.51-5.11a8.061 8.061 0 0 0 2.2-5.3 7.564 7.564 0 0 0-.5-2.64Zm-165.59 23.82c.21-.15.42-.31.62-.47-.06.15-.35.32-.62.47Zm3.21-3.23c-.23.26-.44.52-.67.78a23.366 23.366 0 0 1-2.25 2.2c-.11.1-.23.2-.35.29a.01.01 0 0 0-.01.01 3.804 3.804 0 0 0-.42.22q-.645.39-1.32.72a17.005 17.005 0 0 1-2.71.75 16.8 16.8 0 0 1-2.13.02h-.02a14.823 14.823 0 0 1-1.45-.4c-.24-.12-.47-.26-.7-.4-.09-.08-.17-.16-.22-.21a2.44 2.44 0 0 1-.27-.29.01.01 0 0 0-.01-.01c-.11-.2-.23-.4-.34-.6a.031.031 0 0 1-.01-.02c-.08-.25-.15-.51-.21-.77a12.51 12.51 0 0 1 .01-1.37 13.467 13.467 0 0 1 .54-1.88 11.068 11.068 0 0 1 .69-1.26c.02-.04.12-.2.23-.38.01-.01.01-.01.01-.02.15-.17.3-.35.46-.51.27-.3.56-.56.85-.83a18.022 18.022 0 0 1 1.75-1.01 19.48 19.48 0 0 1 2.93-.79 24.99 24.99 0 0 1 4.41.04 30.301 30.301 0 0 1 4.1 1.01 36.945 36.945 0 0 1-2.77 4.54c-.04.06-.08.12-.12.17Zm-11.12-3.29a2.18 2.18 0 0 1-.31.39 1.409 1.409 0 0 1 .31-.39Z"])</script><script>self.__next_f.push([1,"14:T9d9,"])</script><script>self.__next_f.push([1,"m232.929 317.71-.27 9.42q-.285 10.455-.59 20.92-.315 11.775-.66 23.54-.165 6.075-.34 12.15-.465 16.365-.92 32.72c-.03 1.13-.07 2.25-.1 3.38l-.45 16.23q-.255 8.805-.5 17.61-.18 6.6-.37 13.21l-2.7 95.79a7.648 7.648 0 0 1-7.5 7.5 7.561 7.561 0 0 1-7.5-7.5q.75-26.94 1.52-53.88.675-24.36 1.37-48.72l.45-16.06q.345-12.09.68-24.18c.03-1.13.07-2.25.1-3.38.02-.99.05-1.97.08-2.96l1.32-46.96q.27-9.24.52-18.49l.6-21.08c.09-3.09.17-6.17.26-9.26a7.648 7.648 0 0 1 7.5-7.5 7.561 7.561 0 0 1 7.5 7.5ZM644.357 319.791a893.238 893.238 0 0 1-28.161 87.941c-3.007 7.947-6.083 15.877-9.372 23.712l.756-1.791a54.583 54.583 0 0 1-5.59 10.612q-.229.32-.466.636 1.166-1.49.443-.589c-.254.3-.505.602-.768.895a23.664 23.664 0 0 1-2.249 2.204q-.301.257-.612.504l.938-.73c-.109.258-.873.598-1.11.744a18.254 18.254 0 0 1-2.405 1.218l1.791-.756a19.086 19.086 0 0 1-4.23 1.16l1.993-.267a17.02 17.02 0 0 1-4.298.046l1.994.268a14.002 14.002 0 0 1-3.405-.917l1.791.756a12.012 12.012 0 0 1-1.678-.896c-.272-.177-1.106-.809-.015.024 1.133.866.145.075-.088-.155-.194-.192-.37-.4-.56-.595-.882-.905.997 1.556.397.498a18.182 18.182 0 0 1-.878-1.637l.756 1.792a11.925 11.925 0 0 1-.728-2.651l.268 1.993a13.651 13.651 0 0 1-.003-3.404l-.268 1.993a15.964 15.964 0 0 1 .995-3.68l-.756 1.792a16.73 16.73 0 0 1 1.178-2.299 6.73 6.73 0 0 1 .728-1.071c.05.016-1.268 1.513-.57.757.184-.198.355-.406.54-.602.296-.314.613-.6.925-.898 1.045-.994-1.461.966-.256.18a19.049 19.049 0 0 1 2.75-1.5l-1.792.756a20.311 20.311 0 0 1 4.995-1.34l-1.994.268a25.628 25.628 0 0 1 6.46.076l-1.993-.267a33.21 33.21 0 0 1 7.892 2.22l-1.792-.757c5.39 2.314 10.163 5.75 14.928 9.118a111.95 111.95 0 0 0 14.506 8.907 108.388 108.388 0 0 0 34.622 10.474 103.933 103.933 0 0 0 92.586-36.752 8.078 8.078 0 0 0 2.197-5.304 7.632 7.632 0 0 0-2.197-5.303c-2.752-2.526-7.95-3.239-10.607 0a95.636 95.636 0 0 1-8.106 8.727q-2.018 1.914-4.143 3.71-1.213 1.026-2.46 2.011c-.394.31-1.62 1.138.263-.197-.432.306-.845.64-1.27.954a99.269 99.269 0 0 1-20.333 11.565l1.792-.756a96.836 96.836 0 0 1-24.172 6.623l1.994-.268a97.643 97.643 0 0 1-25.753-.038l1.993.268a99.8 99.8 0 0 1-24.857-6.77l1.792.755a116.025 116.025 0 0 1-21.736-12.59 86.877 86.877 0 0 0-11.113-6.995 42.824 42.824 0 0 0-14.438-4.388c-9.44-1.111-19.057 2.565-24.247 10.72-4.775 7.505-4.714 18.244 1.974 24.625 6.888 6.573 17.319 6.517 25.436 2.406 7.817-3.96 12.513-12.186 15.815-19.942 7.43-17.455 14.01-35.314 20.14-53.263q9.096-26.637 16.498-53.813.917-3.366 1.807-6.74c1.001-3.788-1.261-8.32-5.238-9.225a7.633 7.633 0 0 0-9.226 5.238Z"])</script><script>self.__next_f.push([1,"15:Ta2f,"])</script><script>self.__next_f.push([1,"M519.887 390.06c-8.609-16.792-21.946-30.92-37.632-41.303a114.237 114.237 0 0 0-52.563-18.38q-3.69-.335-7.399-.393c-2.921-.043-46.866 12.632-61.587 22.982a114.295 114.295 0 0 0-35.333 39.527 102.5 102.5 0 0 0-12.126 51.634 113.564 113.564 0 0 0 14.703 51.476 110.475 110.475 0 0 0 36.444 38.745c15.338 9.787 30.745 35.736 48.855 36.652 18.246.923 39.054-23.555 55.695-30.987a104.425 104.425 0 0 0 41.725-34.005 110.25 110.25 0 0 0 19.6-48.948c2.573-18.083 1.374-36.733-4.802-54.016a111.86 111.86 0 0 0-5.58-12.983c-1.78-3.506-6.996-4.796-10.261-2.691a7.68 7.68 0 0 0-2.691 10.261q1.568 3.088 2.915 6.278l-.756-1.792a101.15 101.15 0 0 1 6.877 25.539l-.268-1.994a109.229 109.229 0 0 1-.066 28.682l.267-1.994a109.734 109.734 0 0 1-7.554 27.675l.756-1.792a104.212 104.212 0 0 1-6.672 13.098q-1.923 3.186-4.08 6.222c-.632.888-1.283 1.761-1.94 2.631-.855 1.136 1.168-1.483.283-.37-.15.19-.3.38-.452.57q-.681.852-1.382 1.688a93.613 93.613 0 0 1-10.176 10.383q-1.366 1.193-2.778 2.331c-.469.379-.932.773-1.42 1.125.018-.013 1.579-1.2.655-.51-.29.216-.579.435-.87.651q-2.91 2.156-5.974 4.092a103.485 103.485 0 0 1-14.756 7.713l1.792-.756a109.215 109.215 0 0 1-27.597 7.552l1.994-.268a108.154 108.154 0 0 1-28.589.05l1.994.268a99.835 99.835 0 0 1-25.096-6.784l1.792.756a93.643 93.643 0 0 1-13.416-6.991q-3.174-2-6.184-4.248c-.286-.213-.57-.43-.855-.645-.915-.691.658.51.67.518a19.169 19.169 0 0 1-1.534-1.225q-1.454-1.184-2.862-2.422a101.99 101.99 0 0 1-10.493-10.71q-1.213-1.433-2.374-2.91c-.335-.426-.946-1.29.404.53-.177-.24-.362-.475-.541-.713q-.647-.858-1.276-1.728-2.203-3.048-4.188-6.246a109.29 109.29 0 0 1-7.805-15.108l.756 1.791a106.588 106.588 0 0 1-7.34-26.837l.267 1.994a97.866 97.866 0 0 1-.048-25.636l-.268 1.994a94.673 94.673 0 0 1 6.595-23.959l-.757 1.792a101.557 101.557 0 0 1 7.196-13.857q2.065-3.323 4.377-6.484.526-.719 1.063-1.428c.324-.428 1.215-1.494-.306.388.15-.184.293-.374.44-.56q1.269-1.608 2.6-3.165a107.402 107.402 0 0 1 10.883-11.02q1.474-1.293 2.994-2.53.691-.562 1.391-1.113c.187-.147.376-.29.562-.438-1.998 1.59-.555.432-.102.092q3.134-2.348 6.436-4.46a103.644 103.644 0 0 1 15.386-8.109l-1.791.756c7.76-3.258 42.14-10.949 48.394-10.11l-1.994-.267a106.225 106.225 0 0 1 26.72 7.382l-1.792-.756a110.313 110.313 0 0 1 12.6 6.33q3.044 1.783 5.968 3.762 1.383.936 2.738 1.915.677.489 1.346.989c.248.185.494.372.741.558 1.04.779-1.431-1.129-.342-.267a110.843 110.843 0 0 1 10.368 9.253q2.401 2.445 4.637 5.045 1.147 1.335 2.246 2.708c.365.455 1.605 2.1.085.084.372.493.747.983 1.114 1.48a97.977 97.977 0 0 1 8.392 13.537c1.793 3.498 6.987 4.802 10.261 2.691a7.677 7.677 0 0 0 2.69-10.261Z"])</script><script>self.__next_f.push([1,"16:T61e,M432.497 512.456a3.78 3.78 0 0 1-2.74-6.552l.26-1.03-.103-.247c-3.48-8.297-25.685 14.834-26.645 22.632a30.029 30.029 0 0 0 .527 10.328 120.392 120.392 0 0 1-10.952-50.003 116.202 116.202 0 0 1 .72-12.963q.598-5.293 1.658-10.51a121.787 121.787 0 0 1 24.151-51.617c6.874.383 12.898-.664 13.48-13.986.103-2.37 1.86-4.421 2.248-6.756a30.72 30.72 0 0 1-1.98.183l-.623.032-.077.004a3.745 3.745 0 0 1-3.076-6.101l.85-1.046c.43-.538.872-1.065 1.302-1.603a1.865 1.865 0 0 0 .14-.161c.495-.613.99-1.216 1.485-1.829a10.83 10.83 0 0 0-3.55-3.432c-4.96-2.904-11.802-.893-15.384 3.593-3.593 4.486-4.271 10.78-3.023 16.385a43.398 43.398 0 0 0 6.003 13.383c-.27.344-.549.677-.818 1.022a122.574 122.574 0 0 0-12.793 20.268c1.016-7.939-11.412-36.608-16.218-42.68-5.773-7.295-17.611-4.112-18.628 5.135l-.03.268q1.072.604 2.097 1.283a5.127 5.127 0 0 1-2.067 9.33l-.104.016c-9.556 13.644 21.077 49.155 28.745 41.182a125.11 125.11 0 0 0-6.735 31.692 118.664 118.664 0 0 0 .086 19.16l-.032-.226c-1.704-13.882-30.931-34.522-39.466-32.803-4.917.99-9.76.765-9.013 5.725l.036.237a34.442 34.442 0 0 1 3.862 1.861q1.07.605 2.096 1.283a5.127 5.127 0 0 1-2.067 9.33l-.104.016-.215.033c-4.35 14.966 27.907 39.12 47.517 31.434h.011a125.075 125.075 0 0 0 8.402 24.528h30.015c.107-.333.204-.678.301-1.011a34.102 34.102 0 0 1-8.305-.495c2.227-2.732 4.454-5.486 6.68-8.219a1.861 1.861 0 0 0 .14-.161c1.13-1.399 2.27-2.787 3.4-4.185v-.002a49.952 49.952 0 0 0-1.463-12.725Zm-34.37-67.613.015-.022-.016.043Zm-6.65 59.932-.257-.58c.01-.42.01-.84 0-1.27 0-.119-.022-.237-.022-.355.097.742.183 1.484.29 2.227Z1c:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L7\",null,{\"buildId\":\"0GdVgGOYVHnWTvqfgXExV\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"pyspark-online-compiler\"],\"initialTree\":[\"\",{\"children\":[\"pyspark-online-compiler\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"pyspark-online-compiler\",{\"children\":[\"__PAGE__\",{},[[\"$L8\",[\"$\",\"$L9\",null,{\"props\":{\"params\":{},\"searchParams\":{}},\"Component\":\"$a\"}],null],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/6b786b77af9d8e90.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$La\",null,{\"children\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"pyspark-online-compiler\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}],\"params\":\"$d\"}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/bb98467c3ae26f97.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dcee3e6b25e69456.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"data-theme\":\"nord\",\"className\":\"__className_d65c78\",\"children\":[null,[\"$\",\"$Le\",null,{\"id\":\"Absence-banner\",\"async\":true,\"strategy\":\"afterInteractive\",\"src\":\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3690357492073975\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$Lf\",null,{\"children\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$10\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"section\",null,{\"className\":\"relative bg-base-100 text-base-content h-screen w-full flex flex-col justify-center gap-8 items-center p-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"p-6 bg-white rounded-xl\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"w-56 h-56\",\"viewBox\":\"0 0 860.13137 571.14799\",\"children\":[[\"$\",\"path\",null,{\"fill\":\"#f2f2f2\",\"d\":\"M435.735 160.527c-7.669-12.684-16.757-26.228-30.99-30.37-16.481-4.796-33.412 4.732-47.774 14.135a1392.157 1392.157 0 0 0-123.893 91.283l.043.493 92.451-6.376c22.265-1.535 45.296-3.283 64.972-13.816 7.467-3.996 14.745-9.335 23.206-9.707 10.511-.463 19.677 6.879 26.88 14.549 42.607 45.37 54.937 114.754 102.738 154.616a1516.995 1516.995 0 0 0-107.633-214.807Z\"}],[\"$\",\"path\",null,{\"fill\":\"#e4e4e4\",\"d\":\"$11\"}],[\"$\",\"path\",null,{\"fill\":\"#e4e4e4\",\"d\":\"m560.542 322.285 36.905-13.498 18.323-6.702c5.968-2.183 11.921-4.667 18.09-6.23a28.539 28.539 0 0 1 16.374.208 37.738 37.738 0 0 1 12.77 7.917 103.64 103.64 0 0 1 10.475 11.186c3.99 4.795 7.92 9.64 11.868 14.467q24.442 29.891 48.563 60.042 24.121 30.15 47.92 60.556 23.857 30.48 47.386 61.216 2.882 3.765 5.76 7.534c1.059 1.388 3.449.02 2.374-1.388q-23.702-31.045-47.735-61.835-24.092-30.864-48.516-61.466-24.425-30.601-49.179-60.937-6.167-7.558-12.354-15.099c-3.48-4.24-6.92-8.527-10.737-12.474-7.005-7.245-15.757-13.648-26.234-13.822-6.16-.102-12.121 1.853-17.844 3.923-6.17 2.232-12.325 4.506-18.486 6.76l-37.163 13.592-9.29 3.398c-1.65.603-.937 3.262.73 2.652Z\"}],[\"$\",\"path\",null,{\"fill\":\"#f2f2f2\",\"d\":\"M196.443 170.1c-18.754-9.639-42.771-7.75-60.005 4.291a855.847 855.847 0 0 1 97.37 22.726c-13.282-7.784-23.672-19.98-37.365-27.017ZM136.253 174.358l-3.61 2.935a53.444 53.444 0 0 1 3.795-2.902c-.062-.01-.123-.022-.185-.033ZM661.615 322.42c-3.633-4.422-7.56-9.052-12.994-10.849l-5.073.2a575.436 575.436 0 0 0 153.267 175.221l-135.2-164.572ZM346.15 285.94a37.481 37.481 0 0 0 14.93 20.96c2.82 1.92 6.157 3.761 7.122 7.034a8.379 8.379 0 0 1-.873 6.15 24.884 24.884 0 0 1-3.862 5.041l-.136.512c-6.999-4.147-13.657-9.393-17.523-16.551s-4.405-16.539.342-23.146M579.15 488.94a37.481 37.481 0 0 0 14.93 20.96c2.82 1.92 6.157 3.761 7.122 7.034a8.379 8.379 0 0 1-.873 6.15 24.884 24.884 0 0 1-3.862 5.041l-.136.512c-6.999-4.147-13.657-9.393-17.523-16.551s-4.405-16.539.342-23.146M114.15 474.94a37.481 37.481 0 0 0 14.93 20.96c2.82 1.92 6.157 3.761 7.122 7.034a8.379 8.379 0 0 1-.873 6.15 24.884 24.884 0 0 1-3.862 5.041l-.136.512c-6.999-4.147-13.657-9.393-17.523-16.551s-4.405-16.539.342-23.146\"}],[\"$\",\"circle\",null,{\"cx\":649.249,\"cy\":51,\"r\":51,\"className\":\"fill-primary\"}],[\"$\",\"path\",null,{\"fill\":\"#f0f0f0\",\"d\":\"M741.284 11.87c-24.717-3.34-52.935 10.02-59.341 34.124a21.597 21.597 0 0 0-41.094 2.109l2.83 2.026a372.275 372.275 0 0 0 160.659-.726C787.145 31.334 766 15.21 741.284 11.87ZM635.284 79.87c-24.717-3.34-52.935 10.02-59.341 34.124a21.597 21.597 0 0 0-41.094 2.109l2.83 2.026a372.275 372.275 0 0 0 160.659-.726C681.145 99.334 660 83.21 635.284 79.87Z\"}],[\"$\",\"path\",null,{\"fill\":\"#ccc\",\"d\":\"$12\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"$13\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"$14\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"m719.19 317.71-2.7 95.793-2.686 95.294-1.518 53.883a7.565 7.565 0 0 0 7.5 7.5 7.65 7.65 0 0 0 7.5-7.5l2.7-95.793 2.685-95.294 1.518-53.883a7.565 7.565 0 0 0-7.5-7.5 7.65 7.65 0 0 0-7.5 7.5Z\"}],[\"$\",\"path\",null,{\"d\":\"M459.591 535.935h2.33V429.893h54.328v-2.322H461.92v-44.745h41.956q-.923-1.173-1.899-2.317H461.92v-29.553a65.378 65.378 0 0 0-2.329-.943v30.496H413.94v-37.865c-.782.036-1.552.09-2.329.155v37.71h-36.42v-28.25a54.63 54.63 0 0 0-2.317 1.092v27.158h-30.615v2.317h30.615v44.744h-30.615v2.323h30.615v106.042h2.317V429.893a36.413 36.413 0 0 1 36.42 36.42v69.622h2.33V429.893h45.651Zm-84.4-108.365v-44.744h36.42v44.745Zm38.748 0v-44.744h.914a44.741 44.741 0 0 1 44.738 44.745Z\",\"opacity\":0.2}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"M445.369 504.14a63.059 63.059 0 0 1-20.05 33.7c-.74.64-1.48 1.26-2.25 1.87q-2.805.255-5.57.52c-1.53.14-3.04.29-4.54.43l-.27.03-.19-1.64-.76-6.64a37.623 37.623 0 0 1-3.3-32.44c2.64-7.12 7.42-13.41 12.12-19.65 6.49-8.62 12.8-17.14 13.03-27.65a60.544 60.544 0 0 1 7.9 13.33 16.432 16.432 0 0 0-5.12 3.77c-.41.45-.82 1.08-.54 1.62.24.46.84.57 1.36.63l3.76.39c1 .11 2 .21 3 .32a63.99 63.99 0 0 1 2.45 12.18 61.189 61.189 0 0 1-1.03 19.23Z\"}],[\"$\",\"path\",null,{\"className\":\"fill-primary\",\"d\":\"M478.569 477.93c-5.9 4.29-9.35 10.46-12.03 17.26a16.628 16.628 0 0 0-7.17 4.58c-.41.45-.82 1.08-.54 1.62.24.46.84.57 1.36.63l3.76.39c-2.68 8.04-5.14 16.36-9.88 23.15a36.99 36.99 0 0 1-12.03 10.91 38.492 38.492 0 0 1-4.02 1.99q-7.62.585-14.95 1.25-2.805.255-5.57.52c-1.53.14-3.04.29-4.54.43q-.015-.825 0-1.65a63.304 63.304 0 0 1 15.25-39.86c.45-.52.91-1.03 1.38-1.54a61.792 61.792 0 0 1 16.81-12.7 62.654 62.654 0 0 1 32.17-6.98Z\"}],[\"$\",\"path\",null,{\"className\":\"fill-primary\",\"d\":\"m419.229 535.1-1.15 3.4-.58 1.73c-1.53.14-3.04.29-4.54.43l-.27.03-4.96.51c-.43-.5-.86-1.01-1.28-1.53a62.03 62.03 0 0 1 8.07-87.11c-1.32 6.91.22 13.53 2.75 20.1-.27.11-.53.22-.78.34a16.432 16.432 0 0 0-5.12 3.77c-.41.45-.82 1.08-.54 1.62.24.46.84.57 1.36.63l3.76.39c1 .11 2 .21 3 .32l1.41.15c.07.15.13.29.2.44 2.85 6.18 5.92 12.39 7.65 18.83a43.666 43.666 0 0 1 1.02 4.91 37.604 37.604 0 0 1-10 31.04Z\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"$15\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"$16\"}],[\"$\",\"circle\",null,{\"cx\":95.249,\"cy\":439,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"circle\",null,{\"cx\":227.249,\"cy\":559,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"circle\",null,{\"cx\":728.249,\"cy\":559,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"circle\",null,{\"cx\":755.249,\"cy\":419,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"circle\",null,{\"cx\":723.249,\"cy\":317,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"M264.249 419a10.949 10.949 0 1 1-.21-2.16 10.992 10.992 0 0 1 .21 2.16Z\"}],[\"$\",\"circle\",null,{\"cx\":484.249,\"cy\":349,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"path\",null,{\"fill\":\"#3f3d56\",\"d\":\"M375.249 349a10.949 10.949 0 1 1-.21-2.16 10.992 10.992 0 0 1 .21 2.16ZM233.249 317a10.949 10.949 0 1 1-.21-2.16 10.992 10.992 0 0 1 .21 2.16Z\"}],[\"$\",\"circle\",null,{\"cx\":599.249,\"cy\":443,\"r\":11,\"fill\":\"#3f3d56\"}],[\"$\",\"circle\",null,{\"cx\":426.249,\"cy\":338,\"r\":16,\"fill\":\"#3f3d56\"}],[\"$\",\"path\",null,{\"fill\":\"#cacaca\",\"d\":\"m858.94 570.84-857.75.308a1.19 1.19 0 1 1 0-2.381l857.75-.308a1.19 1.19 0 0 1 0 2.382Z\"}]]}]}],[\"$\",\"p\",null,{\"className\":\"text-lg md:text-xl font-semibold\",\"children\":\"This page doesn't exist üòÖ\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 justify-center\",\"children\":[[\"$\",\"$L17\",null,{\"href\":\"/\",\"className\":\"btn btn-sm\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 20 20\",\"fill\":\"currentColor\",\"className\":\"w-5 h-5\",\"children\":[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"d\":\"M9.293 2.293a1 1 0 011.414 0l7 7A1 1 0 0117 11h-1v6a1 1 0 01-1 1h-2a1 1 0 01-1-1v-3a1 1 0 00-1-1H9a1 1 0 00-1 1v3a1 1 0 01-1 1H5a1 1 0 01-1-1v-6H3a1 1 0 01-.707-1.707l7-7z\",\"clipRule\":\"evenodd\"}]}],\"Home\"]}],[\"$\",\"$L18\",null,{}]]}]]}],\"notFoundStyles\":[]}]}]}],[\"$\",\"$L19\",null,{\"gaId\":\"AW-16685153175\"}]]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L1a\"],\"globalErrorComponent\":\"$1b\",\"missingSlots\":\"$W1c\"}]\n"])</script><script>self.__next_f.push([1,"1a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"name\":\"theme-color\",\"content\":\"#5E81AC\"}],[\"$\",\"meta\",\"2\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"3\",{\"children\":\"PySpark Online Compiler | Spark Playground - Write \u0026 Run Code\"}],[\"$\",\"meta\",\"4\",{\"name\":\"description\",\"content\":\"Write, run, and test PySpark code on Spark Playground‚Äôs online compiler. Access real-world sample datasets to enhance your PySpark skills for data engineering roles.\"}],[\"$\",\"meta\",\"5\",{\"name\":\"application-name\",\"content\":\"Spark Playground\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Spark Playground\"}],[\"$\",\"meta\",\"7\",{\"name\":\"impact-site-verification\",\"content\":\"a8d6651a-7154-4e28-aa0c-d78ea5ccd988\"}],[\"$\",\"link\",\"8\",{\"rel\":\"canonical\",\"href\":\"https://www.sparkplayground.com/pyspark-online-compiler\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:title\",\"content\":\"Spark Playground\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:description\",\"content\":\"Platform to learn, practice, and solve PySpark interview questions to land your next DE role.\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:url\",\"content\":\"https://sparkplayground.com\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:site_name\",\"content\":\"Spark Playground\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:type\",\"content\":\"image/png\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image\",\"content\":\"https://www.sparkplayground.com/opengraph-image.png?d6406e9a3aa550ce\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:creator\",\"content\":\"@rizal_rovins\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:title\",\"content\":\"Spark Playground\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:description\",\"content\":\"Platform to learn, practice, and solve PySpark interview questions to land your next DE role.\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:image:type\",\"content\":\"image/png\"}],[\"$\",\"meta\",\"24\",{\"name\":\"twitter:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"25\",{\"name\":\"twitter:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"26\",{\"name\":\"twitter:image\",\"content\":\"https://www.sparkplayground.com/twitter-image.png?d6406e9a3aa550ce\"}],[\"$\",\"link\",\"27\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"28\",{\"rel\":\"icon\",\"href\":\"/icon.png?8e0bf7a07d09542a\",\"type\":\"image/png\",\"sizes\":\"1200x1200\"}],[\"$\",\"link\",\"29\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?52e4779274dcf9c5\",\"type\":\"image/png\",\"sizes\":\"180x180\"}],[\"$\",\"meta\",\"30\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><style>#nprogress{pointer-events:none}#nprogress .bar{background:#446dff;position:fixed;z-index:1600;top: 0;left:0;width:100%;height:3px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #446dff,0 0 5px #446dff;opacity:1;-webkit-transform:rotate(3deg) translate(0px,-4px);-ms-transform:rotate(3deg) translate(0px,-4px);transform:rotate(3deg) translate(0px,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1600;top: 15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:2px solid transparent;border-top-color:#446dff;border-left-color:#446dff;border-radius:50%;-webkit-animation:nprogress-spinner 400ms linear infinite;animation:nprogress-spinner 400ms linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .bar,.nprogress-custom-parent #nprogress .spinner{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0deg)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}</style><header class="bg-base-200 border-b border-base-300"><script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","name":"Spark Playground","url":"https://www.sparkplayground.com","logo":"https://www.sparkplayground.com/favicon.ico","description":"Spark Playground is an interactive platform designed for aspiring data engineers to learn, practice, and solve real-world PySpark interview questions. It helps users master PySpark skills and prepare for data engineering roles with hands-on coding experience.","contactPoint":{"@type":"ContactPoint","email":"ajulrajar@gmail.com","contactType":"Customer Service","areaServed":"Worldwide","availableLanguage":"English"},"mainEntityOfPage":"https://www.sparkplayground.com"},{"@type":"WebSite","name":"Spark Playground","url":"https://www.sparkplayground.com","description":"A platform for learning PySpark from scratch, practicing real-world interview questions, and using an online compiler to master coding skills for data engineering roles.","potentialAction":{"@type":"SearchAction","target":"https://www.sparkplayground.com/search?q={search_term}","query-input":"required name=search_term"}},{"@type":"Offer","url":"https://www.sparkplayground.com/tutorials","name":"PySpark Tutorials","priceCurrency":"USD","price":"0.00","eligibleRegion":"Worldwide","description":"Comprehensive tutorials that help users learn PySpark from scratch, including topics like dataframes, transformations, actions, and more."},{"@type":"Offer","url":"https://www.sparkplayground.com/pyspark-coding-interview-questions","name":"PySpark Interview Questions","priceCurrency":"USD","price":"0.00","eligibleRegion":"Worldwide","description":"A collection of real-world PySpark interview questions to help users prepare for technical interviews in data engineering roles."},{"@type":"Offer","url":"https://www.sparkplayground.com/pyspark-online-compiler","name":"PySpark Online Compiler","priceCurrency":"USD","price":"0.00","eligibleRegion":"Worldwide","description":"An online compiler that allows users to write, test, and execute PySpark code directly in their browser."},{"@type":"TechArticle","name":"PySpark Cheat Sheet","url":"https://www.sparkplayground.com/pyspark-cheat-sheet","description":"A quick reference for essential PySpark syntax including DataFrame operations, transformations, and actions.","inLanguage":"en","isAccessibleForFree":true,"author":{"@type":"Organization","name":"Spark Playground","url":"https://www.sparkplayground.com"},"mainEntityOfPage":"https://www.sparkplayground.com/pyspark-cheat-sheet"}]}</script><div class="transition-all duration-500 ease-in-out overflow-hidden transform max-h-40 opacity-100 translate-y-0"><div class="text-center bg-gradient-to-r from-primary to-blue-700 text-white px-4 py-2 text-sm justify-between items-center shadow-md"><a class="font-semibold hover:underline text-left flex-1" href="https://www.sparkplayground.com/pricing">üéâ Spark Playground Premium is <strong>50% OFF</strong> - Limited time only! Click here ‚Üí</a></div></div><nav class="container mx-auto max-w-screen-xl"><div class="flex px-8 lg:px-0 items-center justify-between gap-2 lg:items-center lg:justify-center py-3"><div class="flex items-center w-1/5"><a class="flex items-center gap-2 whitespace-nowrap hover:opacity-90 transition-opacity" title="Spark Playground Home" href="https://www.sparkplayground.com/"><img alt="Spark Playground logo" fetchpriority="high" width="32" height="32" decoding="async" data-nimg="1" class="w-8" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=32&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=64&amp;q=75 2x" src="./PySpark Cheat Sheet - Quick Reference Guide_files/icon.png" style="color: transparent;"><span class="font-extrabold text-lg">Spark Playground</span></a></div><div class="flex items-center justify-between lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5"><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6 text-base-content"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:items-center lg:justify-center lg:gap-5 flex-1 w-5/6"><a class="px-2 py-2 rounded-lg hover:bg-base-300 hover:text-base-content transition-colors whitespace-nowrap" href="https://www.sparkplayground.com/tutorials">Learn PySpark</a><div class="px-2 py-2 rounded-lg hover:bg-base-300 hover:text-base-content transition-colors "><div class="relative z-20" data-headlessui-state=""><button class="bg-transparent flex items-center outline-none focus:outline-none active:outline-none" type="button" aria-expanded="false" data-headlessui-state="" id="headlessui-popover-button-:r7:"><span class="text-current whitespace-nowrap">Practice Interview Questions</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 transform transition-transform duration-300 rotate-0"><path fill-rule="evenodd" d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z" clip-rule="evenodd"></path></svg></button></div><div style="position: fixed; top: 1px; left: 1px; width: 1px; height: 0px; padding: 0px; margin: -1px; overflow: hidden; clip: rect(0px, 0px, 0px, 0px); white-space: nowrap; border-width: 0px; display: none;"></div></div><a class="px-2 py-2 rounded-lg hover:bg-base-300 hover:text-base-content transition-colors whitespace-nowrap" href="https://www.sparkplayground.com/pyspark-online-compiler">PySpark Online Compiler</a><a class="px-2 py-2 rounded-lg hover:bg-base-300 hover:text-base-content transition-colors whitespace-nowrap" href="https://www.sparkplayground.com/pyspark-cheat-sheet">Cheat Sheet</a><a class="px-2 py-2 rounded-lg hover:bg-base-300 hover:text-base-content transition-colors whitespace-nowrap" href="https://www.sparkplayground.com/pricing">Pricing</a></div><div class="hidden lg:flex lg:items-center lg:justify-center w-1/6"><button class="btn btn-secondary rounded-full">Sign In</button></div></div></nav><div class="relative z-50 hidden"><div class="fixed inset-y-0 right-0 z-10 w-full px-8 py-4 overflow-y-auto bg-base-200 sm:max-w-sm sm:ring-1 sm:ring-neutral/10 transform origin-right transition ease-in-out duration-300" style=""><div class="flex items-center justify-between"><a class="flex items-center gap-2 shrink-0 " title="Spark Playground hompage" href="https://www.sparkplayground.com/"><img alt="Spark Playground logo" fetchpriority="high" width="32" height="32" decoding="async" data-nimg="1" class="w-8" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=32&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=64&amp;q=75 2x" src="./PySpark Cheat Sheet - Quick Reference Guide_files/icon.png" style="color: transparent;"><span class="font-extrabold text-lg">Spark Playground</span></a><button type="button" class="-m-2.5 rounded-md p-2.5"><span class="sr-only">Close menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12"></path></svg></button></div><div class="flow-root mt-6"><div class="py-4"><div class="flex flex-col gap-y-4 items-start"><a class="link link-hover" title="Learn PySpark" href="https://www.sparkplayground.com/tutorials">Learn PySpark</a><a class="link link-hover" title="Practice Interview Questions" href="https://www.sparkplayground.com/pyspark-coding-interview-questions">Practice Interview Questions</a><a class="link link-hover" title="Blogs &amp; Scenario Based Questions" href="https://www.sparkplayground.com/pyspark-interview-questions">Blogs &amp; Scenario Based Questions</a><a class="link link-hover" title="PySpark Online Compiler" href="https://www.sparkplayground.com/pyspark-online-compiler">PySpark Online Compiler</a><a class="link link-hover" title="Cheat Sheet" href="https://www.sparkplayground.com/pyspark-cheat-sheet">Cheat Sheet</a><a class="link link-hover" title="Pricing" href="https://www.sparkplayground.com/pricing">Pricing</a></div></div><div class="divider"></div><div class="flex flex-col"><button class="btn btn-secondary rounded-full">Sign In</button></div></div></div></div></header><main class="min-h-screen p-8 bg-base-100 text-base-content flex"><aside class="hidden md:block h-screen sticky top-4 w-1/4 bg-base-200 p-2 rounded-lg shadow-md overflow-y-auto overflow-auto" style=""><ul class="list-none ml-2 mt-4 mb-4"><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#create-dataframe" class="text-gray-600 hover:underline text-md font-bold">1. Create DataFrame</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-default-schema" class="text-primary hover:underline text-sm">1.1. With Default Schema</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#explicit-schema" class="text-primary hover:underline text-sm">1.2. Explicit Schema</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#using-a-list-of-dictionaries" class="text-primary hover:underline text-sm">1.3. Using a List of Dictionaries</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#reading-files" class="text-gray-600 hover:underline text-md font-bold">2. Reading Files</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#csv-files" class="text-primary hover:underline text-sm">2.1. CSV Files</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#json-files" class="text-primary hover:underline text-sm">2.2. JSON Files</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#select-drop-rename-columns" class="text-gray-600 hover:underline text-md font-bold">3. Select, Drop, Rename Columns</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#selecting-columns" class="text-primary hover:underline text-sm">3.1. Selecting Columns</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#renaming-columns" class="text-primary hover:underline text-sm">3.2. Renaming Columns</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#adding-columns" class="text-primary hover:underline text-sm">3.3. Adding Columns</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#dropping-columns" class="text-primary hover:underline text-sm">3.4. Dropping Columns</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#filtering" class="text-gray-600 hover:underline text-md font-bold">4. Filtering</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-filtering" class="text-primary hover:underline text-sm">4.1. Basic Filtering</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#filter-with-multiple-conditions" class="text-primary hover:underline text-sm">4.2. Filter with Multiple Conditions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-filters" class="text-primary hover:underline text-sm">4.3. String Filters</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#null-filters" class="text-primary hover:underline text-sm">4.4. Null Filters</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#filter-from-a-list" class="text-primary hover:underline text-sm">4.5. Filter from a List</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#grouping" class="text-gray-600 hover:underline text-md font-bold">5. Grouping</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-aggregations-without-grouping" class="text-primary hover:underline text-sm">5.1. Basic Aggregations without Grouping</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#aggregations-with-grouping" class="text-primary hover:underline text-sm">5.2. Aggregations with Grouping</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#common-aggregation-functions" class="text-primary hover:underline text-sm">5.3. Common Aggregation Functions</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#joins" class="text-gray-600 hover:underline text-md font-bold">6. Joins</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#join-types" class="text-primary hover:underline text-sm">6.1. Join Types</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-syntax" class="text-primary hover:underline text-sm">6.2. Basic Syntax</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-and-time-functions" class="text-gray-600 hover:underline text-md font-bold">7. Date and Time Functions</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-to-date-format" class="text-primary hover:underline text-sm">7.1. String to Date Format</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-to-timestamp-format" class="text-primary hover:underline text-sm">7.2. String to Timestamp Format</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-to-string-format" class="text-primary hover:underline text-sm">7.3. Date to String Format</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#timestamp-to-string-format" class="text-primary hover:underline text-sm">7.4. Timestamp to String Format</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-functions" class="text-primary hover:underline text-sm">7.5. Date Functions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#time-functions" class="text-primary hover:underline text-sm">7.6. Time Functions</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#math-functions" class="text-gray-600 hover:underline text-md font-bold">8. Math Functions</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#simple-arithmetic" class="text-primary hover:underline text-sm">8.1. Simple Arithmetic</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#complex-arithmetic" class="text-primary hover:underline text-sm">8.2. Complex Arithmetic</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-functions" class="text-gray-600 hover:underline text-md font-bold">9. String Functions</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-string-functions" class="text-primary hover:underline text-sm">9.1. Basic String Functions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#trim-and-pad-functions" class="text-primary hover:underline text-sm">9.2. Trim and Pad Functions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#advanced-string-functions" class="text-primary hover:underline text-sm">9.3. Advanced String Functions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#converting-to-other-data-types" class="text-primary hover:underline text-sm">9.4. Converting to Other Data Types</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#window-functions" class="text-gray-600 hover:underline text-md font-bold">10. Window Functions</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-window-functions" class="text-primary hover:underline text-sm">10.1. Basic Window Functions</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-rows-between" class="text-primary hover:underline text-sm">10.2. With Rows Between</a></li></ul></li><li class="mb-2"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#running-sql-queries" class="text-gray-600 hover:underline text-md font-bold">11. Running SQL Queries</a><ul class="list-none ml-6 mt-2"><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-temp-view" class="text-primary hover:underline text-sm">11.1. With Temp View</a></li><li class="mb-1"><a href="https://www.sparkplayground.com/pyspark-cheat-sheet#without-temp-view" class="text-primary hover:underline text-sm">11.2. Without Temp View</a></li></ul></li></ul></aside><section class="w-full lg:w-3/4 ml-0 sm:ml-1 lg:ml-8 md:ml-8"><header class="flex justify-between items-center mb-4"><h1 class="text-2xl font-bold text-primary">PySpark Cheat Sheet: Quick Reference for Beginners &amp; Pros</h1></header><div class="bg-base-100" data-color-mode="light"><div class="wmde-markdown wmde-markdown-color bg-base-100" style="background: rgb(237, 239, 244); padding: 0px;">
<p>Welcome to the <strong>PySpark Syntax Cheat Sheet</strong>! This page is designed to provide a quick reference to essential PySpark functions and operations. <strong>Click</strong> the links on the left to quickly navigate through the sections.</p>
<p>This page is still a <strong>work in progress</strong>, so check back for updates as we continue to add more content. If you have feedback or find something essential missing, submit a request by clicking on the <strong>"Help Us Improve"</strong> button at the bottom right!</p>
<h2 id="create-dataframe"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#create-dataframe"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Create DataFrame</h2>
<h3 id="with-default-schema"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-default-schema"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With Default Schema</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
</span><span class="code-line">
</span><span class="code-line">spark <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"Example"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"Alice"</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"Bob"</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"age"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Example&quot;).getOrCreate()

data = [(1, &quot;Alice&quot;, 29), (2, &quot;Bob&quot;, 35)]
df = spark.createDataFrame(data, [&quot;id&quot;, &quot;name&quot;, &quot;age&quot;])
df.show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="explicit-schema"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#explicit-schema"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Explicit Schema</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> StructType<span class="token punctuation">,</span> StructField<span class="token punctuation">,</span> IntegerType<span class="token punctuation">,</span> StringType
</span><span class="code-line">
</span><span class="code-line">schema <span class="token operator">=</span> StructType<span class="token punctuation">(</span><span class="token punctuation">[</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> StringType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> schema<span class="token punctuation">)</span>
</span><span class="code-line">df<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Schema as a string</span>
</span><span class="code-line">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"Alice"</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"Bob"</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</span><span class="code-line">schema <span class="token operator">=</span> <span class="token string">"id INT, name STRING, age INT"</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Schema String with Float and Boolean Types</span>
</span><span class="code-line">schema <span class="token operator">=</span> <span class="token string">"id INT, name STRING, salary FLOAT, is_active BOOLEAN"</span>
</span><span class="code-line">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"Alice"</span><span class="token punctuation">,</span> <span class="token number">50000.75</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"Bob"</span><span class="token punctuation">,</span> <span class="token number">60000.50</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Schema String with Date and Timestamp</span>
</span><span class="code-line"><span class="token keyword">from</span> datetime <span class="token keyword">import</span> date<span class="token punctuation">,</span> datetime
</span><span class="code-line">schema <span class="token operator">=</span> <span class="token string">"id INT, name STRING, join_date DATE, last_login TIMESTAMP"</span>
</span><span class="code-line">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"Alice"</span><span class="token punctuation">,</span> date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> datetime<span class="token punctuation">(</span><span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">        <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"Bob"</span><span class="token punctuation">,</span> date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> datetime<span class="token punctuation">(</span><span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.types import StructType, StructField, IntegerType, StringType

schema = StructType([
    StructField(&quot;id&quot;, IntegerType(), True),
    StructField(&quot;name&quot;, StringType(), True),
    StructField(&quot;age&quot;, IntegerType(), True)
])

df = spark.createDataFrame(data, schema)
df.printSchema()
df.show()

# Schema as a string
data = [(1, &quot;Alice&quot;, 29), (2, &quot;Bob&quot;, 35)]
schema = &quot;id INT, name STRING, age INT&quot;
df = spark.createDataFrame(data, schema=schema)

# Schema String with Float and Boolean Types
schema = &quot;id INT, name STRING, salary FLOAT, is_active BOOLEAN&quot;
data = [(1, &quot;Alice&quot;, 50000.75, True), (2, &quot;Bob&quot;, 60000.50, False)]
df = spark.createDataFrame(data, schema=schema)

# Schema String with Date and Timestamp
from datetime import date, datetime
schema = &quot;id INT, name STRING, join_date DATE, last_login TIMESTAMP&quot;
data = [(1, &quot;Alice&quot;, date(2023, 1, 15), datetime(2024, 3, 10, 14, 30, 0)),
        (2, &quot;Bob&quot;, date(2023, 1, 15), datetime(2024, 3, 10, 14, 30, 0))]
df = spark.createDataFrame(data, schema=schema)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="using-a-list-of-dictionaries"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#using-a-list-of-dictionaries"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Using a List of Dictionaries</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
</span><span class="code-line">
</span><span class="code-line">spark <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"Example"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">data <span class="token operator">=</span> <span class="token punctuation">[</span>
</span><span class="code-line">    <span class="token punctuation">{</span><span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Alice"</span><span class="token punctuation">,</span> <span class="token string">"age"</span><span class="token punctuation">:</span> <span class="token number">29</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token punctuation">{</span><span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Bob"</span><span class="token punctuation">,</span> <span class="token string">"age"</span><span class="token punctuation">:</span> <span class="token number">35</span><span class="token punctuation">}</span>
</span><span class="code-line"><span class="token punctuation">]</span>
</span><span class="code-line">
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Example&quot;).getOrCreate()

data = [
    {&quot;id&quot;: 1, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 29},
    {&quot;id&quot;: 2, &quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 35}
]

df = spark.createDataFrame(data)
df.show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h2 id="reading-files"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#reading-files"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>Reading Files</strong></h2>
<h3 id="csv-files"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#csv-files"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>CSV Files</strong></h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment">#Basic CSV files</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/path/to/sample.csv"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#csv with header</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"header"</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">"/path/to/sample.csv"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># multiple options</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"inferSchema"</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"delimiter"</span><span class="token punctuation">,</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">"/path/to/sample.csv"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># with defined schema</span>
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> StructType<span class="token punctuation">,</span> StructField<span class="token punctuation">,</span> StringType<span class="token punctuation">,</span> IntegerType
</span><span class="code-line">schema <span class="token operator">=</span> StructType<span class="token punctuation">(</span><span class="token punctuation">[</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> StringType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>schema<span class="token punctuation">(</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/path/to/sample.csv"</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="#Basic CSV files
df = spark.read.format(&quot;csv&quot;).load(&quot;/path/to/sample.csv&quot;)

#csv with header
df = spark.read.option(&quot;header&quot;,True).csv(&quot;/path/to/sample.csv&quot;)

# multiple options
df = spark.read.option(&quot;inferSchema&quot;,True).option(&quot;delimiter&quot;,&quot;,&quot;).csv(&quot;/path/to/sample.csv&quot;)

# with defined schema
from pyspark.sql.types import StructType, StructField, StringType, IntegerType
schema = StructType([
    StructField(&quot;name&quot;, StringType(), True),
    StructField(&quot;age&quot;, IntegerType(), True)
])
df = spark.read.format(&quot;csv&quot;).schema(schema).load(&quot;/path/to/sample.csv&quot;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="json-files"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#json-files"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>JSON Files</strong></h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Basic JSON file</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/path/to/sample.json"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># JSON with multi-line records</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"multiline"</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"/path/to/sample.json"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># JSON with a defined schema</span>
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> StructType<span class="token punctuation">,</span> StructField<span class="token punctuation">,</span> StringType<span class="token punctuation">,</span> IntegerType
</span><span class="code-line">
</span><span class="code-line">schema <span class="token operator">=</span> StructType<span class="token punctuation">(</span><span class="token punctuation">[</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> StringType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    StructField<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>schema<span class="token punctuation">(</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/path/to/sample.json"</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Basic JSON file
df = spark.read.format(&quot;json&quot;).load(&quot;/path/to/sample.json&quot;)

# JSON with multi-line records
df = spark.read.option(&quot;multiline&quot;, True).json(&quot;/path/to/sample.json&quot;)

# JSON with a defined schema
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField(&quot;name&quot;, StringType(), True),
    StructField(&quot;age&quot;, IntegerType(), True)
])

df = spark.read.format(&quot;json&quot;).schema(schema).load(&quot;/path/to/sample.json&quot;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h2 id="select-drop-rename-columns"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#select-drop-rename-columns"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>Select, Drop, Rename Columns</strong></h2>
<h3 id="selecting-columns"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#selecting-columns"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Selecting Columns</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Select single column</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Select multiple columns</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"age"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Select columns dynamically</span>
</span><span class="code-line">columns_to_select <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"department"</span><span class="token punctuation">]</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token operator">*</span>columns_to_select<span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Select single column
df = df.select(&quot;name&quot;)

# Select multiple columns
df = df.select(&quot;name&quot;, &quot;age&quot;)

# Select columns dynamically
columns_to_select = [&quot;name&quot;, &quot;department&quot;]
df = df.select(*columns_to_select)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="renaming-columns"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#renaming-columns"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Renaming Columns</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Rename a column</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumnRenamed<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"full_name"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Rename multiple columns with chained calls</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumnRenamed<span class="token punctuation">(</span><span class="token string">"old_col1"</span><span class="token punctuation">,</span> <span class="token string">"new_col1"</span><span class="token punctuation">)</span>\
</span><span class="code-line">       <span class="token punctuation">.</span>withColumnRenamed<span class="token punctuation">(</span><span class="token string">"old_col2"</span><span class="token punctuation">,</span> <span class="token string">"new_col2"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Rename columns using select and alias</span>
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> col
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>select<span class="token punctuation">(</span>
</span><span class="code-line">    col<span class="token punctuation">(</span><span class="token string">"old_column_name1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"new_column_name1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    col<span class="token punctuation">(</span><span class="token string">"old_column_name2"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"new_column_name2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token comment"># Add more columns as needed</span>
</span><span class="code-line"><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Rename a column
df = df.withColumnRenamed(&quot;name&quot;, &quot;full_name&quot;)

# Rename multiple columns with chained calls
df = df.withColumnRenamed(&quot;old_col1&quot;, &quot;new_col1&quot;)\
       .withColumnRenamed(&quot;old_col2&quot;, &quot;new_col2&quot;)

# Rename columns using select and alias
from pyspark.sql.functions import col
df = df.select(
    col(&quot;old_column_name1&quot;).alias(&quot;new_column_name1&quot;),
    col(&quot;old_column_name2&quot;).alias(&quot;new_column_name2&quot;),
    # Add more columns as needed
)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="adding-columns"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#adding-columns"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Adding Columns</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> col<span class="token punctuation">,</span> lit<span class="token punctuation">,</span> expr<span class="token punctuation">,</span> when
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Add a new column with a constant value</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"country"</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">"USA"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Add a new column with a calculated value</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"salary_after_bonus"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1.1</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Add a column using an SQL expression</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"tax"</span><span class="token punctuation">,</span> expr<span class="token punctuation">(</span><span class="token string">"salary * 0.2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Add a column with conditional logic</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"high_earner"</span><span class="token punctuation">,</span> when<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">55000</span><span class="token punctuation">,</span> <span class="token string">"Yes"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token string">"No"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Case When with multiple conditions</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span>
</span><span class="code-line">    <span class="token string">"salary_category"</span><span class="token punctuation">,</span>
</span><span class="code-line">    when<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">60000</span><span class="token punctuation">,</span> <span class="token string">"Low"</span><span class="token punctuation">)</span>
</span><span class="code-line">    <span class="token punctuation">.</span>when<span class="token punctuation">(</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">60000</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">90000</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Medium"</span><span class="token punctuation">)</span>
</span><span class="code-line">    <span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token string">"High"</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Add multiple columns at once</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumns<span class="token punctuation">(</span><span class="token punctuation">{</span>
</span><span class="code-line">    <span class="token string">"bonus"</span><span class="token punctuation">:</span> col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token string">"net_salary"</span><span class="token punctuation">:</span> col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.2</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">}</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span></code><div class="copied" data-code="from pyspark.sql.functions import col, lit, expr, when

# Add a new column with a constant value
df = df.withColumn(&quot;country&quot;, lit(&quot;USA&quot;))

# Add a new column with a calculated value
df = df.withColumn(&quot;salary_after_bonus&quot;, col(&quot;salary&quot;) * 1.1)

# Add a column using an SQL expression
df = df.withColumn(&quot;tax&quot;, expr(&quot;salary * 0.2&quot;))

# Add a column with conditional logic
df = df.withColumn(&quot;high_earner&quot;, when(col(&quot;salary&quot;) &gt; 55000, &quot;Yes&quot;).otherwise(&quot;No&quot;))

# Case When with multiple conditions
df = df.withColumn(
    &quot;salary_category&quot;,
    when(col(&quot;salary&quot;) &lt; 60000, &quot;Low&quot;)
    .when((col(&quot;salary&quot;) &gt;= 60000) &amp; (col(&quot;salary&quot;) &lt; 90000), &quot;Medium&quot;)
    .otherwise(&quot;High&quot;)
)

# Add multiple columns at once
df = df.withColumns({
    &quot;bonus&quot;: col(&quot;salary&quot;) * 0.1,
    &quot;net_salary&quot;: col(&quot;salary&quot;) - (col(&quot;salary&quot;) * 0.2)
})

"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="dropping-columns"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#dropping-columns"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Dropping Columns</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Drop a column</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Drop multiple columns</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'column1'</span><span class="token punctuation">,</span> <span class="token string">'column2'</span><span class="token punctuation">,</span> <span class="token string">'column3'</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Drop a column
df = df.drop(&quot;department&quot;)

# Drop multiple columns
df = df.drop(&#39;column1&#39;, &#39;column2&#39;, &#39;column3&#39;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h2 id="filtering"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#filtering"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>Filtering</strong></h2>
<p>You can refer to columns using any of these notations: <code>df.age</code> , <code>df['age']</code>, <code>col('age')</code></p>
<h3 id="basic-filtering"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-filtering"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic Filtering</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Filter on &gt;, &lt;, &gt;=, &lt;=, == condition</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>age <span class="token operator">&gt;</span> <span class="token number">30</span><span class="token punctuation">)</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">30</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Using col() function</span>
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> col
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">30</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Filter on &gt;, &lt;, &gt;=, &lt;=, == condition
df_filtered = df.filter(df.age &gt; 30)
df_filtered = df.filter(df[&#39;age&#39;] &gt; 30)

# Using col() function
from pyspark.sql.functions import col
df_filtered = df.filter(col(&quot;age&quot;) &gt; 30)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="filter-with-multiple-conditions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#filter-with-multiple-conditions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Filter with Multiple Conditions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Multiple conditions require parentheses around each condition</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># AND condition ( &amp; )</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>age <span class="token operator">&gt;</span> <span class="token number">25</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df<span class="token punctuation">.</span>department <span class="token operator">==</span> <span class="token string">"Engineering"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># OR condition ( | )</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>age <span class="token operator">&lt;</span> <span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span>df<span class="token punctuation">.</span>department <span class="token operator">==</span> <span class="token string">"Finance"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Multiple conditions require parentheses around each condition

# AND condition ( &amp; )
df_filtered = df.filter((df.age &gt; 25) &amp; (df.department == &quot;Engineering&quot;))
# OR condition ( | )
df_filtered = df.filter((df.age &lt; 30) | (df.department == &quot;Finance&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="string-filters"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-filters"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>String Filters</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Filter rows where department equals 'Marketing'</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>department <span class="token operator">==</span> <span class="token string">"Marketing"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Case-insensitive filter</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>like<span class="token punctuation">(</span><span class="token string">"MARKETING"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Contains a substring</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">"Engineer"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Filter rows where the name starts with 'A'</span>
</span><span class="code-line">df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Filter rows where the name ends with 'e'</span>
</span><span class="code-line">df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">"e"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Filter rows where the name matches a regex</span>
</span><span class="code-line">df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rlike<span class="token punctuation">(</span><span class="token string">"^A.*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Filter rows where department equals &#39;Marketing&#39;
df_filtered = df.filter(df.department == &quot;Marketing&quot;)

# Case-insensitive filter
df_filtered = df.filter(col(&quot;department&quot;).like(&quot;MARKETING&quot;))

# Contains a substring
df_filtered = df.filter(col(&quot;department&quot;).contains(&quot;Engineer&quot;))

# Filter rows where the name starts with &#39;A&#39;
df.filter(col(&quot;name&quot;).startswith(&quot;A&quot;)).show()

# Filter rows where the name ends with &#39;e&#39;
df.filter(col(&quot;name&quot;).endswith(&quot;e&quot;)).show()

# Filter rows where the name matches a regex
df.filter(col(&quot;name&quot;).rlike(&quot;^A.*&quot;)).show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="null-filters"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#null-filters"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Null Filters</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Filter rows where a column is null</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>department<span class="token punctuation">.</span>isNull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># Filter rows where a column is not null</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>department<span class="token punctuation">.</span>isNotNull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Filter rows where a column is null
df_filtered = df.filter(df.department.isNull())
# Filter rows where a column is not null
df_filtered = df.filter(df.department.isNotNull())
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="filter-from-a-list"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#filter-from-a-list"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Filter from a List</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Filter rows where department is in a list</span>
</span><span class="code-line">departments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Engineering"</span><span class="token punctuation">,</span> <span class="token string">"Finance"</span><span class="token punctuation">]</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>departments<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># Negate the filter (not in list)</span>
</span><span class="code-line">df_filtered <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token operator">~</span>col<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>departments<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Filter rows where department is in a list
departments = [&quot;Engineering&quot;, &quot;Finance&quot;]
df_filtered = df.filter(col(&quot;department&quot;).isin(departments))
# Negate the filter (not in list)
df_filtered = df.filter(~col(&quot;department&quot;).isin(departments))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h2 id="grouping"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#grouping"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>Grouping</strong></h2>
<p>Import the required functions</p>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> count<span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">,</span> avg<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">,</span> countDistinct<span class="token punctuation">,</span> collect_list<span class="token punctuation">,</span> collect_set
</span></code><div class="copied" data-code="from pyspark.sql.functions import count, sum, avg, min, max, countDistinct, collect_list, collect_set
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="basic-aggregations-without-grouping"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-aggregations-without-grouping"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic Aggregations without Grouping</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment">#Count rows</span>
</span><span class="code-line">df<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#Count Distinct Values in a column</span>
</span><span class="code-line">df<span class="token punctuation">.</span>select<span class="token punctuation">(</span>countDistinct<span class="token punctuation">(</span><span class="token string">"Department"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#Sum</span>
</span><span class="code-line">df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#Multiple Aggregations</span>
</span><span class="code-line">df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="#Count rows
df.count()

#Count Distinct Values in a column
df.select(countDistinct(&quot;Department&quot;)).show()

#Sum
df.select(sum(&quot;Salary&quot;)).show()

#Multiple Aggregations
df.select(min(&quot;Salary&quot;), max(&quot;Salary&quot;)).show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="aggregations-with-grouping"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#aggregations-with-grouping"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Aggregations with Grouping</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment">#Group by a single column</span>
</span><span class="code-line">df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"Department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#GroupBy with Multiple Columns</span>
</span><span class="code-line">df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"Department"</span><span class="token punctuation">,</span> <span class="token string">"Employee"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#Group by with multiple aggregations</span>
</span><span class="code-line">df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"Department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>agg<span class="token punctuation">(</span>
</span><span class="code-line">    count<span class="token punctuation">(</span><span class="token string">"Employee"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"Employee_Count"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    avg<span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"Average_Salary"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"Max_Salary"</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#Filter after aggregation</span>
</span><span class="code-line">df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"Department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>agg<span class="token punctuation">(</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"Salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>alias<span class="token punctuation">(</span><span class="token string">"Total_Salary"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token string">"Total_Salary &gt; 8000"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span></code><div class="copied" data-code="#Group by a single column
df.groupBy(&quot;Department&quot;).sum(&quot;Salary&quot;).show()

#GroupBy with Multiple Columns
df.groupBy(&quot;Department&quot;, &quot;Employee&quot;).sum(&quot;Salary&quot;).show()

#Group by with multiple aggregations
df.groupBy(&quot;Department&quot;).agg(
    count(&quot;Employee&quot;).alias(&quot;Employee_Count&quot;),
    avg(&quot;Salary&quot;).alias(&quot;Average_Salary&quot;),
    max(&quot;Salary&quot;).alias(&quot;Max_Salary&quot;)
)

#Filter after aggregation
df.groupBy(&quot;Department&quot;).agg(sum(&quot;Salary&quot;).alias(&quot;Total_Salary&quot;)).filter(&quot;Total_Salary &gt; 8000&quot;).show()

"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="common-aggregation-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#common-aggregation-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Common Aggregation Functions</h3>


















































<table><thead><tr><th><strong>Function</strong></th><th><strong>Description</strong></th><th><strong>Example</strong></th></tr></thead><tbody><tr><td><code>count()</code></td><td>Counts rows in a group.</td><td><code>groupBy("Department").count()</code></td></tr><tr><td><code>sum()</code></td><td>Sums values in a group.</td><td><code>groupBy("Department").sum("Salary")</code></td></tr><tr><td><code>avg()</code> / <code>mean()</code></td><td>Calculates average values.</td><td><code>groupBy("Department").avg("Salary")</code></td></tr><tr><td><code>min()</code></td><td>Finds the minimum value.</td><td><code>groupBy("Department").min("Salary")</code></td></tr><tr><td><code>max()</code></td><td>Finds the maximum value.</td><td><code>groupBy("Department").max("Salary")</code></td></tr><tr><td><code>countDistinct()</code></td><td>Counts distinct values in a group.</td><td><code>countDistinct("Employee")</code></td></tr><tr><td><code>collect_list()</code></td><td>Collects all values into a list.</td><td><code>collect_list("Employee")</code></td></tr><tr><td><code>collect_set()</code></td><td>Collects unique values into a set.</td><td><code>collect_set("Employee")</code></td></tr></tbody></table>
<hr>
<h2 id="joins"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#joins"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Joins</h2>
<h3 id="join-types"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#join-types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><strong>Join Types</strong></h3>













































<table><thead><tr><th><strong>Join Type</strong></th><th><strong>Syntax</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><strong>inner</strong></td><td><code>how="inner"</code></td><td>Returns matching rows from both DataFrames based on the join condition.</td></tr><tr><td><strong>outer</strong> (full)</td><td><code>how="outer</code></td><td>Returns all rows, with <code>NULL</code> where no match is found in either DataFrame.</td></tr><tr><td><strong>left</strong> (left_outer)</td><td><code>how="left"</code></td><td>Returns all rows from the left DataFrame, with <code>NULL</code> for unmatched rows in the right.</td></tr><tr><td><strong>right</strong> (right_outer)</td><td><code>how="right"</code></td><td>Returns all rows from the right DataFrame, with <code>NULL</code> for unmatched rows in the left.</td></tr><tr><td><strong>left_semi</strong></td><td><code>how="left_semi"</code></td><td>This is just an inner join of the two DataFrames, but only returns columns of left DataFrame.</td></tr><tr><td><strong>left_anti</strong></td><td><code>how="left_anti"</code></td><td>Returns rows from the left DataFrame that do not have a match in the right.</td></tr><tr><td><strong>cross</strong></td><td><code>df1.crossJoin(df2)</code></td><td>Returns the Cartesian product of rows from both DataFrames (no join condition).</td></tr></tbody></table>
<h3 id="basic-syntax"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-syntax"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic Syntax</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Basic Join</span>
</span><span class="code-line">df1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>df2<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">"inner"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Join on Multiple Columns</span>
</span><span class="code-line">df1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>df2<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"col1"</span><span class="token punctuation">,</span> <span class="token string">"col2"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">"left"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Conditional Join</span>
</span><span class="code-line">df1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>df2<span class="token punctuation">,</span> <span class="token punctuation">(</span>df1<span class="token punctuation">.</span><span class="token builtin">id</span> <span class="token operator">==</span> df2<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df2<span class="token punctuation">.</span>city <span class="token operator">==</span> <span class="token string">"New York"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">"inner"</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># Multiple join conditions require parentheses around each condition</span>
</span><span class="code-line">joined_df <span class="token operator">=</span> sales_df<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
</span><span class="code-line">    customers_df<span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token punctuation">(</span>sales_df<span class="token punctuation">[</span><span class="token string">"customer_id"</span><span class="token punctuation">]</span> <span class="token operator">==</span> customers_df<span class="token punctuation">[</span><span class="token string">"customer_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>sales_df<span class="token punctuation">[</span><span class="token string">"region"</span><span class="token punctuation">]</span> <span class="token operator">==</span> customers_df<span class="token punctuation">[</span><span class="token string">"region"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</span><span class="code-line">    <span class="token string">"inner"</span>
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Select ALL columns from df1, and SOME columns from df2 (useful for left joins)</span>
</span><span class="code-line">result <span class="token operator">=</span> df1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>df2<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">"left"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"*"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> df2<span class="token punctuation">[</span><span class="token string">"state"</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> df2<span class="token punctuation">[</span><span class="token string">"town"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Broadcast Join for Small DataFrames</span>
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> broadcast
</span><span class="code-line">df1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>broadcast<span class="token punctuation">(</span>df2<span class="token punctuation">)</span><span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">"inner"</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Basic Join
df1.join(df2, on=&quot;id&quot;, how=&quot;inner&quot;)

# Join on Multiple Columns
df1.join(df2, on=[&quot;col1&quot;, &quot;col2&quot;], how=&quot;left&quot;)

# Conditional Join
df1.join(df2, (df1.id == df2.id) &amp; (df2.city == &quot;New York&quot;), how=&quot;inner&quot;)
# Multiple join conditions require parentheses around each condition
joined_df = sales_df.join(
    customers_df,
    (sales_df[&quot;customer_id&quot;] == customers_df[&quot;customer_id&quot;]) &amp; (sales_df[&quot;region&quot;] == customers_df[&quot;region&quot;]),
    &quot;inner&quot;
)

# Select ALL columns from df1, and SOME columns from df2 (useful for left joins)
result = df1.join(df2, on=&quot;id&quot;, how=&quot;left&quot;).select(df1[&quot;*&quot;], df2[&quot;state&quot;] , df2[&quot;town&quot;])

# Broadcast Join for Small DataFrames
from pyspark.sql.functions import broadcast
df1.join(broadcast(df2), on=&quot;id&quot;, how=&quot;inner&quot;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<hr>
<h2 id="date-and-time-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-and-time-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Date and Time Functions</h2>
<h3 id="string-to-date-format"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-to-date-format"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>String to Date Format</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> to_date
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Convert string date to date type (using "yyyy-MM-dd")</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 (as a Date type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_parsed1"</span><span class="token punctuation">,</span> to_date<span class="token punctuation">(</span><span class="token string">"date_str"</span><span class="token punctuation">,</span> <span class="token string">"yyyy-MM-dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Convert string date to date type (using "dd-MMM-yyyy")</span>
</span><span class="code-line"><span class="token comment"># Input: "25-Jan-2025"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 (as a Date type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_parsed2"</span><span class="token punctuation">,</span> to_date<span class="token punctuation">(</span><span class="token string">"date_str"</span><span class="token punctuation">,</span> <span class="token string">"dd-MMM-yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Convert string date to date type (using "MM/dd/yyyy")</span>
</span><span class="code-line"><span class="token comment"># Input: "01/25/2025"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 (as a Date type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_parsed3"</span><span class="token punctuation">,</span> to_date<span class="token punctuation">(</span><span class="token string">"date_str"</span><span class="token punctuation">,</span> <span class="token string">"MM/dd/yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Convert string date to date type (using "yyyy.MM.dd")</span>
</span><span class="code-line"><span class="token comment"># Input: "2025.01.25"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 (as a Date type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_parsed4"</span><span class="token punctuation">,</span> to_date<span class="token punctuation">(</span><span class="token string">"date_str"</span><span class="token punctuation">,</span> <span class="token string">"yyyy.MM.dd"</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.functions import to_date

# 1. Convert string date to date type (using &quot;yyyy-MM-dd&quot;)
# Input: &quot;2025-01-25&quot;
# Output: 2025-01-25 (as a Date type)
df = df.withColumn(&quot;date_parsed1&quot;, to_date(&quot;date_str&quot;, &quot;yyyy-MM-dd&quot;))

# 2. Convert string date to date type (using &quot;dd-MMM-yyyy&quot;)
# Input: &quot;25-Jan-2025&quot;
# Output: 2025-01-25 (as a Date type)
df = df.withColumn(&quot;date_parsed2&quot;, to_date(&quot;date_str&quot;, &quot;dd-MMM-yyyy&quot;))

# 3. Convert string date to date type (using &quot;MM/dd/yyyy&quot;)
# Input: &quot;01/25/2025&quot;
# Output: 2025-01-25 (as a Date type)
df = df.withColumn(&quot;date_parsed3&quot;, to_date(&quot;date_str&quot;, &quot;MM/dd/yyyy&quot;))

# 4. Convert string date to date type (using &quot;yyyy.MM.dd&quot;)
# Input: &quot;2025.01.25&quot;
# Output: 2025-01-25 (as a Date type)
df = df.withColumn(&quot;date_parsed4&quot;, to_date(&quot;date_str&quot;, &quot;yyyy.MM.dd&quot;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="string-to-timestamp-format"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-to-timestamp-format"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>String to Timestamp Format</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> to_timestamp
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Convert string timestamp to timestamp type (using "yyyy-MM-dd HH:mm:ss")</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 10:15:00 (as a Timestamp type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"timestamp_parsed1"</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp_str"</span><span class="token punctuation">,</span> <span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Convert string timestamp to timestamp type (using "dd-MMM-yyyy HH:mm:ss")</span>
</span><span class="code-line"><span class="token comment"># Input: "25-Jan-2025 10:15:00"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 10:15:00 (as a Timestamp type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"timestamp_parsed2"</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp_str"</span><span class="token punctuation">,</span> <span class="token string">"dd-MMM-yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Convert string timestamp to timestamp type (using "MM/dd/yyyy HH:mm:ss")</span>
</span><span class="code-line"><span class="token comment"># Input: "01/25/2025 10:15:00"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 10:15:00 (as a Timestamp type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"timestamp_parsed3"</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp_str"</span><span class="token punctuation">,</span> <span class="token string">"MM/dd/yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Convert string timestamp to timestamp type (using "yyyy.MM.dd HH:mm:ss")</span>
</span><span class="code-line"><span class="token comment"># Input: "2025.01.25 10:15:00"</span>
</span><span class="code-line"><span class="token comment"># Output: 2025-01-25 10:15:00 (as a Timestamp type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"timestamp_parsed4"</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp_str"</span><span class="token punctuation">,</span> <span class="token string">"yyyy.MM.dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.functions import to_timestamp

# 1. Convert string timestamp to timestamp type (using &quot;yyyy-MM-dd HH:mm:ss&quot;)
# Input: &quot;2025-01-25 10:15:00&quot;
# Output: 2025-01-25 10:15:00 (as a Timestamp type)
df = df.withColumn(&quot;timestamp_parsed1&quot;, to_timestamp(&quot;timestamp_str&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;))

# 2. Convert string timestamp to timestamp type (using &quot;dd-MMM-yyyy HH:mm:ss&quot;)
# Input: &quot;25-Jan-2025 10:15:00&quot;
# Output: 2025-01-25 10:15:00 (as a Timestamp type)
df = df.withColumn(&quot;timestamp_parsed2&quot;, to_timestamp(&quot;timestamp_str&quot;, &quot;dd-MMM-yyyy HH:mm:ss&quot;))

# 3. Convert string timestamp to timestamp type (using &quot;MM/dd/yyyy HH:mm:ss&quot;)
# Input: &quot;01/25/2025 10:15:00&quot;
# Output: 2025-01-25 10:15:00 (as a Timestamp type)
df = df.withColumn(&quot;timestamp_parsed3&quot;, to_timestamp(&quot;timestamp_str&quot;, &quot;MM/dd/yyyy HH:mm:ss&quot;))

# 4. Convert string timestamp to timestamp type (using &quot;yyyy.MM.dd HH:mm:ss&quot;)
# Input: &quot;2025.01.25 10:15:00&quot;
# Output: 2025-01-25 10:15:00 (as a Timestamp type)
df = df.withColumn(&quot;timestamp_parsed4&quot;, to_timestamp(&quot;timestamp_str&quot;, &quot;yyyy.MM.dd HH:mm:ss&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="date-to-string-format"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-to-string-format"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Date to String Format</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> date_format
</span><span class="code-line"><span class="token comment"># 1. Format date as "yyyy-MM-dd"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025-01-25" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date1"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"yyyy-MM-dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Format date as "dd-MMM-yyyy"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "25-Jan-2025" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date2"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"dd-MMM-yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Format date as "MM/dd/yyyy"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "01/25/2025" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date3"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"MM/dd/yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Format date as "dd/MM/yyyy"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "25/01/2025" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date4"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"dd/MM/yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Format date as "MMMM dd, yyyy"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "January 25, 2025" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date5"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"MMMM dd, yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Format date as "EEE, dd MMM yyyy"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "Sun, 25 Jan 2025" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date6"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"EEE, dd MMM yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Format date as "yyyy/MM/dd"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025/01/25" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date7"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"yyyy/MM/dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 8. Format date as "yyyy.MM.dd"</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025.01.25" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_date8"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">,</span> <span class="token string">"yyyy.MM.dd"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.functions import date_format
# 1. Format date as &quot;yyyy-MM-dd&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;2025-01-25&quot; (String Type)
df = df.withColumn(&quot;formatted_date1&quot;, date_format(&quot;date_parsed&quot;, &quot;yyyy-MM-dd&quot;))

# 2. Format date as &quot;dd-MMM-yyyy&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;25-Jan-2025&quot; (String Type)
df = df.withColumn(&quot;formatted_date2&quot;, date_format(&quot;date_parsed&quot;, &quot;dd-MMM-yyyy&quot;))

# 3. Format date as &quot;MM/dd/yyyy&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;01/25/2025&quot; (String Type)
df = df.withColumn(&quot;formatted_date3&quot;, date_format(&quot;date_parsed&quot;, &quot;MM/dd/yyyy&quot;))

# 4. Format date as &quot;dd/MM/yyyy&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;25/01/2025&quot; (String Type)
df = df.withColumn(&quot;formatted_date4&quot;, date_format(&quot;date_parsed&quot;, &quot;dd/MM/yyyy&quot;))

# 5. Format date as &quot;MMMM dd, yyyy&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;January 25, 2025&quot; (String Type)
df = df.withColumn(&quot;formatted_date5&quot;, date_format(&quot;date_parsed&quot;, &quot;MMMM dd, yyyy&quot;))

# 6. Format date as &quot;EEE, dd MMM yyyy&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;Sun, 25 Jan 2025&quot; (String Type)
df = df.withColumn(&quot;formatted_date6&quot;, date_format(&quot;date_parsed&quot;, &quot;EEE, dd MMM yyyy&quot;))

# 7. Format date as &quot;yyyy/MM/dd&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;2025/01/25&quot; (String Type)
df = df.withColumn(&quot;formatted_date7&quot;, date_format(&quot;date_parsed&quot;, &quot;yyyy/MM/dd&quot;))

# 8. Format date as &quot;yyyy.MM.dd&quot;
# Input: 2025-01-25 (Date Type)
# Output: &quot;2025.01.25&quot; (String Type)
df = df.withColumn(&quot;formatted_date8&quot;, date_format(&quot;date_parsed&quot;, &quot;yyyy.MM.dd&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="timestamp-to-string-format"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#timestamp-to-string-format"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Timestamp to String Format</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> date_format
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Format timestamp as "yyyy-MM-dd HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025-01-25 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp1"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Format timestamp as "dd-MMM-yyyy HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "25-Jan-2025 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp2"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"dd-MMM-yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Format timestamp as "MM/dd/yyyy HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "01/25/2025 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp3"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"MM/dd/yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Format timestamp as "dd/MM/yyyy HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "25/01/2025 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp4"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"dd/MM/yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Format timestamp as "MMMM dd, yyyy HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "January 25, 2025 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp5"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"MMMM dd, yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Format timestamp as "EEE, dd MMM yyyy HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "Sun, 25 Jan 2025 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp6"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"EEE, dd MMM yyyy HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Format timestamp as "yyyy/MM/dd HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025/01/25 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp7"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"yyyy/MM/dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 8. Format timestamp as "yyyy.MM.dd HH:mm:ss"</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25 10:15:00" (Timestamp Type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025.01.25 10:15:00" (String Type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"formatted_timestamp8"</span><span class="token punctuation">,</span> date_format<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token string">"yyyy.MM.dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Show the resulting DataFrame</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span>truncate<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span></code><div class="copied" data-code="from pyspark.sql.functions import date_format

# 1. Format timestamp as &quot;yyyy-MM-dd HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;2025-01-25 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp1&quot;, date_format(&quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;))

# 2. Format timestamp as &quot;dd-MMM-yyyy HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;25-Jan-2025 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp2&quot;, date_format(&quot;timestamp&quot;, &quot;dd-MMM-yyyy HH:mm:ss&quot;))

# 3. Format timestamp as &quot;MM/dd/yyyy HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;01/25/2025 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp3&quot;, date_format(&quot;timestamp&quot;, &quot;MM/dd/yyyy HH:mm:ss&quot;))

# 4. Format timestamp as &quot;dd/MM/yyyy HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;25/01/2025 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp4&quot;, date_format(&quot;timestamp&quot;, &quot;dd/MM/yyyy HH:mm:ss&quot;))

# 5. Format timestamp as &quot;MMMM dd, yyyy HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;January 25, 2025 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp5&quot;, date_format(&quot;timestamp&quot;, &quot;MMMM dd, yyyy HH:mm:ss&quot;))

# 6. Format timestamp as &quot;EEE, dd MMM yyyy HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;Sun, 25 Jan 2025 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp6&quot;, date_format(&quot;timestamp&quot;, &quot;EEE, dd MMM yyyy HH:mm:ss&quot;))

# 7. Format timestamp as &quot;yyyy/MM/dd HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;2025/01/25 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp7&quot;, date_format(&quot;timestamp&quot;, &quot;yyyy/MM/dd HH:mm:ss&quot;))

# 8. Format timestamp as &quot;yyyy.MM.dd HH:mm:ss&quot;
# Input: &quot;2025-01-25 10:15:00&quot; (Timestamp Type)
# Output: &quot;2025.01.25 10:15:00&quot; (String Type)
df = df.withColumn(&quot;formatted_timestamp8&quot;, date_format(&quot;timestamp&quot;, &quot;yyyy.MM.dd HH:mm:ss&quot;))

# Show the resulting DataFrame
df.show(truncate=False)

"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="date-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#date-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Date Functions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> <span class="token punctuation">(</span>
</span><span class="code-line">    current_date<span class="token punctuation">,</span> date_add<span class="token punctuation">,</span> date_sub<span class="token punctuation">,</span> datediff<span class="token punctuation">,</span> add_months<span class="token punctuation">,</span>
</span><span class="code-line">    trunc<span class="token punctuation">,</span> date_format<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> dayofmonth<span class="token punctuation">,</span> next_day<span class="token punctuation">,</span> last_day
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Current date</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; Current system date (e.g., "2025-01-25")</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"current_date"</span><span class="token punctuation">,</span> current_date<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Add 10 days to the date</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025-02-04"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_plus_10"</span><span class="token punctuation">,</span> date_add<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Subtract 5 days from the date</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025-01-20"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_minus_5"</span><span class="token punctuation">,</span> date_sub<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Difference in days from current date</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; Number of days difference from today (e.g., "-5")</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"days_diff"</span><span class="token punctuation">,</span> datediff<span class="token punctuation">(</span>current_date<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Add 2 months to the date</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025-03-25"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"add_months"</span><span class="token punctuation">,</span> add_months<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Extract year</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"year"</span><span class="token punctuation">,</span> year<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Extract month</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "1"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"month"</span><span class="token punctuation">,</span> month<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 8. Extract day of the month</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "25"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"day"</span><span class="token punctuation">,</span> dayofmonth<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 9. Extract day of the week (1 = Sunday, 7 = Saturday)</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25"</span>
</span><span class="code-line"><span class="token comment"># Output: 7 (Saturday)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"day_of_week"</span><span class="token punctuation">,</span> dayofweek<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 10. Extract week of the year</span>
</span><span class="code-line"><span class="token comment"># Input: "2025-01-25"</span>
</span><span class="code-line"><span class="token comment"># Output: 4 (Week 4 of the year)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"week_of_year"</span><span class="token punctuation">,</span> weekofyear<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 11. Truncate to the first day of the month</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025-01-01"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"trunc_month"</span><span class="token punctuation">,</span> trunc<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">,</span> <span class="token string">"MM"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 12. Next specified day of the week</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; Next Monday (e.g., "2025-01-27")</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"next_monday"</span><span class="token punctuation">,</span> next_day<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">,</span> <span class="token string">"Monday"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 13. Last day of the month</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25" -&gt; "2025-01-31"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"last_day_month"</span><span class="token punctuation">,</span> last_day<span class="token punctuation">(</span><span class="token string">"date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    current_date, date_add, date_sub, datediff, add_months,
    trunc, date_format, year, month, dayofmonth, next_day, last_day
)

# 1. Current date
# &quot;2025-01-25&quot; -&gt; Current system date (e.g., &quot;2025-01-25&quot;)
df = df.withColumn(&quot;current_date&quot;, current_date())

# 2. Add 10 days to the date
# &quot;2025-01-25&quot; -&gt; &quot;2025-02-04&quot;
df = df.withColumn(&quot;date_plus_10&quot;, date_add(&quot;date&quot;, 10))

# 3. Subtract 5 days from the date
# &quot;2025-01-25&quot; -&gt; &quot;2025-01-20&quot;
df = df.withColumn(&quot;date_minus_5&quot;, date_sub(&quot;date&quot;, 5))

# 4. Difference in days from current date
# &quot;2025-01-25&quot; -&gt; Number of days difference from today (e.g., &quot;-5&quot;)
df = df.withColumn(&quot;days_diff&quot;, datediff(current_date(), &quot;date&quot;))

# 5. Add 2 months to the date
# &quot;2025-01-25&quot; -&gt; &quot;2025-03-25&quot;
df = df.withColumn(&quot;add_months&quot;, add_months(&quot;date&quot;, 2))

# 6. Extract year
# &quot;2025-01-25&quot; -&gt; &quot;2025&quot;
df = df.withColumn(&quot;year&quot;, year(&quot;date&quot;))

# 7. Extract month
# &quot;2025-01-25&quot; -&gt; &quot;1&quot;
df = df.withColumn(&quot;month&quot;, month(&quot;date&quot;))

# 8. Extract day of the month
# &quot;2025-01-25&quot; -&gt; &quot;25&quot;
df = df.withColumn(&quot;day&quot;, dayofmonth(&quot;date&quot;))

# 9. Extract day of the week (1 = Sunday, 7 = Saturday)
# Input: &quot;2025-01-25&quot;
# Output: 7 (Saturday)
df = df.withColumn(&quot;day_of_week&quot;, dayofweek(&quot;date&quot;))

# 10. Extract week of the year
# Input: &quot;2025-01-25&quot;
# Output: 4 (Week 4 of the year)
df = df.withColumn(&quot;week_of_year&quot;, weekofyear(&quot;date&quot;))

# 11. Truncate to the first day of the month
# &quot;2025-01-25&quot; -&gt; &quot;2025-01-01&quot;
df = df.withColumn(&quot;trunc_month&quot;, trunc(&quot;date&quot;, &quot;MM&quot;))

# 12. Next specified day of the week
# &quot;2025-01-25&quot; -&gt; Next Monday (e.g., &quot;2025-01-27&quot;)
df = df.withColumn(&quot;next_monday&quot;, next_day(&quot;date&quot;, &quot;Monday&quot;))

# 13. Last day of the month
# &quot;2025-01-25&quot; -&gt; &quot;2025-01-31&quot;
df = df.withColumn(&quot;last_day_month&quot;, last_day(&quot;date&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="time-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#time-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Time Functions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> <span class="token punctuation">(</span>
</span><span class="code-line">    current_timestamp<span class="token punctuation">,</span> hour<span class="token punctuation">,</span> minute<span class="token punctuation">,</span> second<span class="token punctuation">,</span> unix_timestamp<span class="token punctuation">,</span> from_unixtime
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Current timestamp</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25 10:15:00" -&gt; Current system timestamp (e.g., "2025-01-25 10:15:00")</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"current_timestamp"</span><span class="token punctuation">,</span> current_timestamp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Extract hour</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25 10:15:00" -&gt; "10"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"hour"</span><span class="token punctuation">,</span> hour<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Extract minute</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25 10:15:00" -&gt; "15"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"minute"</span><span class="token punctuation">,</span> minute<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Extract second</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25 10:15:00" -&gt; "00"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"second"</span><span class="token punctuation">,</span> second<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Convert date to Unix timestamp</span>
</span><span class="code-line"><span class="token comment"># "2025-01-25 10:15:00" -&gt; "1737763200"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"unix_timestamp"</span><span class="token punctuation">,</span> unix_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Convert Unix timestamp to readable date</span>
</span><span class="code-line"><span class="token comment"># "1737763200" -&gt; "2025-01-25 10:15:00"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"from_unix"</span><span class="token punctuation">,</span> from_unixtime<span class="token punctuation">(</span>unix_timestamp<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    current_timestamp, hour, minute, second, unix_timestamp, from_unixtime
)

# 1. Current timestamp
# &quot;2025-01-25 10:15:00&quot; -&gt; Current system timestamp (e.g., &quot;2025-01-25 10:15:00&quot;)
df = df.withColumn(&quot;current_timestamp&quot;, current_timestamp())

# 2. Extract hour
# &quot;2025-01-25 10:15:00&quot; -&gt; &quot;10&quot;
df = df.withColumn(&quot;hour&quot;, hour(&quot;timestamp&quot;))

# 3. Extract minute
# &quot;2025-01-25 10:15:00&quot; -&gt; &quot;15&quot;
df = df.withColumn(&quot;minute&quot;, minute(&quot;timestamp&quot;))

# 4. Extract second
# &quot;2025-01-25 10:15:00&quot; -&gt; &quot;00&quot;
df = df.withColumn(&quot;second&quot;, second(&quot;timestamp&quot;))

# 5. Convert date to Unix timestamp
# &quot;2025-01-25 10:15:00&quot; -&gt; &quot;1737763200&quot;
df = df.withColumn(&quot;unix_timestamp&quot;, unix_timestamp(&quot;timestamp&quot;))

# 6. Convert Unix timestamp to readable date
# &quot;1737763200&quot; -&gt; &quot;2025-01-25 10:15:00&quot;
df = df.withColumn(&quot;from_unix&quot;, from_unixtime(unix_timestamp(&quot;timestamp&quot;)))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<hr>
<h2 id="math-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#math-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Math Functions</h2>
<h3 id="simple-arithmetic"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#simple-arithmetic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simple Arithmetic</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># 1. Add two columns</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10, col2 = 5</span>
</span><span class="code-line"><span class="token comment"># Output: 15 (col1 + col2)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">+</span> col<span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Subtract two columns</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10, col2 = 5</span>
</span><span class="code-line"><span class="token comment"># Output: 5 (col1 - col2)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"difference"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">-</span> col<span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Multiply two columns</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10, col2 = 5</span>
</span><span class="code-line"><span class="token comment"># Output: 50 (col1 * col2)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"product"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">*</span> col<span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Divide two columns</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10, col2 = 5</span>
</span><span class="code-line"><span class="token comment"># Output: 2.0 (col1 / col2)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"quotient"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">/</span> col<span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Add a constant to a column</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10</span>
</span><span class="code-line"><span class="token comment"># Output: 15 (col1 + 5)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"sum_with_constant"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">5</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Subtract a constant from a column</span>
</span><span class="code-line"><span class="token comment"># Input: col1 = 10</span>
</span><span class="code-line"><span class="token comment"># Output: 5 (col1 - 5)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"difference_with_constant"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">5</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# 1. Add two columns
# Input: col1 = 10, col2 = 5
# Output: 15 (col1 + col2)
df = df.withColumn(&quot;sum&quot;, col(&quot;col1&quot;) + col(&quot;col2&quot;))

# 2. Subtract two columns
# Input: col1 = 10, col2 = 5
# Output: 5 (col1 - col2)
df = df.withColumn(&quot;difference&quot;, col(&quot;col1&quot;) - col(&quot;col2&quot;))

# 3. Multiply two columns
# Input: col1 = 10, col2 = 5
# Output: 50 (col1 * col2)
df = df.withColumn(&quot;product&quot;, col(&quot;col1&quot;) * col(&quot;col2&quot;))

# 4. Divide two columns
# Input: col1 = 10, col2 = 5
# Output: 2.0 (col1 / col2)
df = df.withColumn(&quot;quotient&quot;, col(&quot;col1&quot;) / col(&quot;col2&quot;))

# 5. Add a constant to a column
# Input: col1 = 10
# Output: 15 (col1 + 5)
df = df.withColumn(&quot;sum_with_constant&quot;, col(&quot;col1&quot;) + 5)

# 6. Subtract a constant from a column
# Input: col1 = 10
# Output: 5 (col1 - 5)
df = df.withColumn(&quot;difference_with_constant&quot;, col(&quot;col1&quot;) - 5)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="complex-arithmetic"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#complex-arithmetic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Complex Arithmetic</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> <span class="token punctuation">(</span>
</span><span class="code-line">    <span class="token builtin">abs</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">,</span> floor<span class="token punctuation">,</span> ceil<span class="token punctuation">,</span> exp<span class="token punctuation">,</span> log<span class="token punctuation">,</span> sqrt<span class="token punctuation">,</span> <span class="token builtin">pow</span>
</span><span class="code-line"><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 1. Absolute value</span>
</span><span class="code-line"><span class="token comment"># Input: -2.71</span>
</span><span class="code-line"><span class="token comment"># Output: 2.71</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"abs_value"</span><span class="token punctuation">,</span> <span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Round the number to 2 decimal places</span>
</span><span class="code-line"><span class="token comment"># Input: 3.14159</span>
</span><span class="code-line"><span class="token comment"># Output: 3.14</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rounded_value"</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Floor (round down to the nearest integer)</span>
</span><span class="code-line"><span class="token comment"># Input: 3.14</span>
</span><span class="code-line"><span class="token comment"># Output: 3</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"floor_value"</span><span class="token punctuation">,</span> floor<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Ceil (round up to the nearest integer)</span>
</span><span class="code-line"><span class="token comment"># Input: 3.14</span>
</span><span class="code-line"><span class="token comment"># Output: 4</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"ceil_value"</span><span class="token punctuation">,</span> ceil<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Exponent (e raised to the power of the value)</span>
</span><span class="code-line"><span class="token comment"># Input: 2.0</span>
</span><span class="code-line"><span class="token comment"># Output: 7.389056</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"exp_value"</span><span class="token punctuation">,</span> exp<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Logarithm (log base e of the value)</span>
</span><span class="code-line"><span class="token comment"># Input: 2.718</span>
</span><span class="code-line"><span class="token comment"># Output: 0.999896</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"log_value"</span><span class="token punctuation">,</span> log<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Square root</span>
</span><span class="code-line"><span class="token comment"># Input: 16</span>
</span><span class="code-line"><span class="token comment"># Output: 4</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"sqrt_value"</span><span class="token punctuation">,</span> sqrt<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 8. Power (raise the value to the power of 2)</span>
</span><span class="code-line"><span class="token comment"># Input: 3</span>
</span><span class="code-line"><span class="token comment"># Output: 9</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"pow_value"</span><span class="token punctuation">,</span> <span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.functions import (
    abs, round, floor, ceil, exp, log, sqrt, pow
)

# 1. Absolute value
# Input: -2.71
# Output: 2.71
df = df.withColumn(&quot;abs_value&quot;, abs(&quot;value&quot;))

# 2. Round the number to 2 decimal places
# Input: 3.14159
# Output: 3.14
df = df.withColumn(&quot;rounded_value&quot;, round(&quot;value&quot;, 2))

# 3. Floor (round down to the nearest integer)
# Input: 3.14
# Output: 3
df = df.withColumn(&quot;floor_value&quot;, floor(&quot;value&quot;))

# 4. Ceil (round up to the nearest integer)
# Input: 3.14
# Output: 4
df = df.withColumn(&quot;ceil_value&quot;, ceil(&quot;value&quot;))

# 5. Exponent (e raised to the power of the value)
# Input: 2.0
# Output: 7.389056
df = df.withColumn(&quot;exp_value&quot;, exp(&quot;value&quot;))

# 6. Logarithm (log base e of the value)
# Input: 2.718
# Output: 0.999896
df = df.withColumn(&quot;log_value&quot;, log(&quot;value&quot;))

# 7. Square root
# Input: 16
# Output: 4
df = df.withColumn(&quot;sqrt_value&quot;, sqrt(&quot;value&quot;))

# 8. Power (raise the value to the power of 2)
# Input: 3
# Output: 9
df = df.withColumn(&quot;pow_value&quot;, pow(&quot;value&quot;, 2))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<hr>
<h2 id="string-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#string-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>String Functions</h2>
<h3 id="basic-string-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-string-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic String Functions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># 1. Concatenate two strings</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world" + " !!!"</span>
</span><span class="code-line"><span class="token comment"># Output: "hello world !!!"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"concatenated_2_cols"</span><span class="token punctuation">,</span> concat<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"col1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"col2"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"concatenated_col_with_lit"</span><span class="token punctuation">,</span> concat<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">" !!!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Concatenate columns with a separator (Space)</span>
</span><span class="code-line"><span class="token comment"># Input: ("John", "Doe", "30")</span>
</span><span class="code-line"><span class="token comment"># Output: "John Doe 30"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">,</span> concat_ws<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Concatenate columns with a separator (Comma)</span>
</span><span class="code-line"><span class="token comment"># Input: ("John", "Doe", "30")</span>
</span><span class="code-line"><span class="token comment"># Output: "John, Doe, 30"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"full_name_comma"</span><span class="token punctuation">,</span> concat_ws<span class="token punctuation">(</span><span class="token string">", "</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Concatenate with a custom string</span>
</span><span class="code-line"><span class="token comment"># Input: ("John", "Doe")</span>
</span><span class="code-line"><span class="token comment"># Output: "Name: John Doe"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> concat_ws<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">"Name: "</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Check if string contains a substring</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world" -&gt; "world"</span>
</span><span class="code-line"><span class="token comment"># Output: True</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"contains_world"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contains<span class="token punctuation">(</span><span class="token string">"world"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"contains_world2"</span><span class="token punctuation">,</span> contains<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">"world"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Check if string starts with a specific substring</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world" -&gt; "hello"</span>
</span><span class="code-line"><span class="token comment"># Output: True</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"starts_with_hello"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"starts_with_hello2"</span><span class="token punctuation">,</span> startswith<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Check if string ends with a specific substring</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world" -&gt; "world"</span>
</span><span class="code-line"><span class="token comment"># Output: True</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"ends_with_world"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">"world"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"ends_with_world2"</span><span class="token punctuation">,</span> endswith<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lit<span class="token punctuation">(</span><span class="token string">"world"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 8. Capitalize the first letter of each word</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world"</span>
</span><span class="code-line"><span class="token comment"># Output: "Hello World"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"initcap_text"</span><span class="token punctuation">,</span> initcap<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 9. Convert string to uppercase</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world"</span>
</span><span class="code-line"><span class="token comment"># Output: "HELLO WORLD"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"upper_text"</span><span class="token punctuation">,</span> upper<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 10. Convert string to lowercase</span>
</span><span class="code-line"><span class="token comment"># Input: "HELLO WORLD"</span>
</span><span class="code-line"><span class="token comment"># Output: "hello world"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"lower_text"</span><span class="token punctuation">,</span> lower<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 11. Get the length of the string</span>
</span><span class="code-line"><span class="token comment"># Input: "hello world"</span>
</span><span class="code-line"><span class="token comment"># Output: 11</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"length_of_text"</span><span class="token punctuation">,</span> length<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# 1. Concatenate two strings
# Input: &quot;hello world&quot; + &quot; !!!&quot;
# Output: &quot;hello world !!!&quot;
df = df.withColumn(&quot;concatenated_2_cols&quot;, concat(col(&quot;col1&quot;), col(&quot;col2&quot;)))
df = df.withColumn(&quot;concatenated_col_with_lit&quot;, concat(col(&quot;text&quot;), lit(&quot; !!!&quot;)))

# 2. Concatenate columns with a separator (Space)
# Input: (&quot;John&quot;, &quot;Doe&quot;, &quot;30&quot;)
# Output: &quot;John Doe 30&quot;
df = df.withColumn(&quot;full_name&quot;, concat_ws(&quot; &quot;, col(&quot;first_name&quot;), col(&quot;last_name&quot;), col(&quot;age&quot;)))

# 3. Concatenate columns with a separator (Comma)
# Input: (&quot;John&quot;, &quot;Doe&quot;, &quot;30&quot;)
# Output: &quot;John, Doe, 30&quot;
df = df.withColumn(&quot;full_name_comma&quot;, concat_ws(&quot;, &quot;, col(&quot;first_name&quot;), col(&quot;last_name&quot;), col(&quot;age&quot;)))

# 4. Concatenate with a custom string
# Input: (&quot;John&quot;, &quot;Doe&quot;)
# Output: &quot;Name: John Doe&quot;
df = df.withColumn(&quot;name&quot;, concat_ws(&quot;&quot;, lit(&quot;Name: &quot;), col(&quot;first_name&quot;), lit(&quot; &quot;), col(&quot;last_name&quot;)))

# 5. Check if string contains a substring
# Input: &quot;hello world&quot; -&gt; &quot;world&quot;
# Output: True
df = df.withColumn(&quot;contains_world&quot;, col(&quot;text&quot;).contains(&quot;world&quot;))
df = df.withColumn(&quot;contains_world2&quot;, contains(col(&quot;text&quot;), lit(&quot;world&quot;)))

# 6. Check if string starts with a specific substring
# Input: &quot;hello world&quot; -&gt; &quot;hello&quot;
# Output: True
df = df.withColumn(&quot;starts_with_hello&quot;, col(&quot;text&quot;).startswith(&quot;hello&quot;))
df = df.withColumn(&quot;starts_with_hello2&quot;, startswith(col(&quot;text&quot;), lit(&quot;hello&quot;)))

# 7. Check if string ends with a specific substring
# Input: &quot;hello world&quot; -&gt; &quot;world&quot;
# Output: True
df = df.withColumn(&quot;ends_with_world&quot;, col(&quot;text&quot;).endswith(&quot;world&quot;))
df = df.withColumn(&quot;ends_with_world2&quot;, endswith(col(&quot;text&quot;), lit(&quot;world&quot;)))

# 8. Capitalize the first letter of each word
# Input: &quot;hello world&quot;
# Output: &quot;Hello World&quot;
df = df.withColumn(&quot;initcap_text&quot;, initcap(col(&quot;text&quot;)))

# 9. Convert string to uppercase
# Input: &quot;hello world&quot;
# Output: &quot;HELLO WORLD&quot;
df = df.withColumn(&quot;upper_text&quot;, upper(col(&quot;text&quot;)))

# 10. Convert string to lowercase
# Input: &quot;HELLO WORLD&quot;
# Output: &quot;hello world&quot;
df = df.withColumn(&quot;lower_text&quot;, lower(col(&quot;text&quot;)))

# 11. Get the length of the string
# Input: &quot;hello world&quot;
# Output: 11
df = df.withColumn(&quot;length_of_text&quot;, length(col(&quot;text&quot;)))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="trim-and-pad-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#trim-and-pad-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Trim and Pad Functions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># 1. Trim: Remove both leading and trailing spaces from first_name</span>
</span><span class="code-line"><span class="token comment"># Input: "   John   "</span>
</span><span class="code-line"><span class="token comment"># Output: "John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"trimmed_first_name"</span><span class="token punctuation">,</span> trim<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Ltrim: Remove leading spaces from first_name</span>
</span><span class="code-line"><span class="token comment"># Input: "   John"</span>
</span><span class="code-line"><span class="token comment"># Output: "John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"ltrim_first_name"</span><span class="token punctuation">,</span> ltrim<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Rtrim: Remove trailing spaces from last_name</span>
</span><span class="code-line"><span class="token comment"># Input: "Doe   "</span>
</span><span class="code-line"><span class="token comment"># Output: "Doe"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rtrim_last_name"</span><span class="token punctuation">,</span> rtrim<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Lpad: Pad first_name with spaces on the left to make the length 10</span>
</span><span class="code-line"><span class="token comment"># Input: "John"</span>
</span><span class="code-line"><span class="token comment"># Output: "      John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"lpad_first_name"</span><span class="token punctuation">,</span> lpad<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Rpad: Pad last_name with spaces on the right to make the length 10</span>
</span><span class="code-line"><span class="token comment"># Input: "Doe"</span>
</span><span class="code-line"><span class="token comment"># Output: "Doe       "</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rpad_last_name"</span><span class="token punctuation">,</span> rpad<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Lpad with a custom padding character: Pad first_name with "0" on the left to make the length 10</span>
</span><span class="code-line"><span class="token comment"># Input: "John"</span>
</span><span class="code-line"><span class="token comment"># Output: "00000John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"lpad_first_name_zeros"</span><span class="token punctuation">,</span> lpad<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">"0"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Rpad with a custom padding character: Pad last_name with "0" on the right to make the length 10</span>
</span><span class="code-line"><span class="token comment"># Input: "Doe"</span>
</span><span class="code-line"><span class="token comment"># Output: "Doe0000000"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rpad_last_name_zeros"</span><span class="token punctuation">,</span> rpad<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">"0"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# 1. Trim: Remove both leading and trailing spaces from first_name
# Input: &quot;   John   &quot;
# Output: &quot;John&quot;
df = df.withColumn(&quot;trimmed_first_name&quot;, trim(col(&quot;first_name&quot;)))

# 2. Ltrim: Remove leading spaces from first_name
# Input: &quot;   John&quot;
# Output: &quot;John&quot;
df = df.withColumn(&quot;ltrim_first_name&quot;, ltrim(col(&quot;first_name&quot;)))

# 3. Rtrim: Remove trailing spaces from last_name
# Input: &quot;Doe   &quot;
# Output: &quot;Doe&quot;
df = df.withColumn(&quot;rtrim_last_name&quot;, rtrim(col(&quot;last_name&quot;)))

# 4. Lpad: Pad first_name with spaces on the left to make the length 10
# Input: &quot;John&quot;
# Output: &quot;      John&quot;
df = df.withColumn(&quot;lpad_first_name&quot;, lpad(col(&quot;first_name&quot;), 10, &quot; &quot;))

# 5. Rpad: Pad last_name with spaces on the right to make the length 10
# Input: &quot;Doe&quot;
# Output: &quot;Doe       &quot;
df = df.withColumn(&quot;rpad_last_name&quot;, rpad(col(&quot;last_name&quot;), 10, &quot; &quot;))

# 6. Lpad with a custom padding character: Pad first_name with &quot;0&quot; on the left to make the length 10
# Input: &quot;John&quot;
# Output: &quot;00000John&quot;
df = df.withColumn(&quot;lpad_first_name_zeros&quot;, lpad(col(&quot;first_name&quot;), 10, &quot;0&quot;))

# 7. Rpad with a custom padding character: Pad last_name with &quot;0&quot; on the right to make the length 10
# Input: &quot;Doe&quot;
# Output: &quot;Doe0000000&quot;
df = df.withColumn(&quot;rpad_last_name_zeros&quot;, rpad(col(&quot;last_name&quot;), 10, &quot;0&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="advanced-string-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#advanced-string-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Advanced String Functions</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># 1. Substring: Extract substring from the full_name starting from position 1 (inclusive) with length 4</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"substring_example"</span><span class="token punctuation">,</span> substring<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Substring: Extract substring from the full_name starting from position 6 (inclusive) with length 3</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "Doe"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"substring_name"</span><span class="token punctuation">,</span> substring<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Substring: Extract last 2 characters of the full_name</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "30"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"substring_age"</span><span class="token punctuation">,</span> substring<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Split: Split the full_name into first and last names based on the "_" separator</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: ["John", "Doe", "30"]</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"split_name"</span><span class="token punctuation">,</span> split<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Split: Split the full_name into first and last names based on the "_" separator and get the first part (first name)</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "John"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"first_name"</span><span class="token punctuation">,</span> split<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Split: Split the full_name into first and last names and get the second part (last name)</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "Doe"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"last_name"</span><span class="token punctuation">,</span> split<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Split: Split the full_name and get the third part (age)</span>
</span><span class="code-line"><span class="token comment"># Input: "John_Doe_30"</span>
</span><span class="code-line"><span class="token comment"># Output: "30"</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> split<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"full_name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# 1. Substring: Extract substring from the full_name starting from position 1 (inclusive) with length 4
# Input: &quot;John_Doe_30&quot;
# Output: &quot;John&quot;
df = df.withColumn(&quot;substring_example&quot;, substring(col(&quot;full_name&quot;), 1, 4))

# 2. Substring: Extract substring from the full_name starting from position 6 (inclusive) with length 3
# Input: &quot;John_Doe_30&quot;
# Output: &quot;Doe&quot;
df = df.withColumn(&quot;substring_name&quot;, substring(col(&quot;full_name&quot;), 6, 3))

# 3. Substring: Extract last 2 characters of the full_name
# Input: &quot;John_Doe_30&quot;
# Output: &quot;30&quot;
df = df.withColumn(&quot;substring_age&quot;, substring(col(&quot;full_name&quot;), -2, 2))

# 4. Split: Split the full_name into first and last names based on the &quot;_&quot; separator
# Input: &quot;John_Doe_30&quot;
# Output: [&quot;John&quot;, &quot;Doe&quot;, &quot;30&quot;]
df = df.withColumn(&quot;split_name&quot;, split(col(&quot;full_name&quot;), &quot;_&quot;))

# 5. Split: Split the full_name into first and last names based on the &quot;_&quot; separator and get the first part (first name)
# Input: &quot;John_Doe_30&quot;
# Output: &quot;John&quot;
df = df.withColumn(&quot;first_name&quot;, split(col(&quot;full_name&quot;), &quot;_&quot;)[0])

# 6. Split: Split the full_name into first and last names and get the second part (last name)
# Input: &quot;John_Doe_30&quot;
# Output: &quot;Doe&quot;
df = df.withColumn(&quot;last_name&quot;, split(col(&quot;full_name&quot;), &quot;_&quot;)[1])

# 7. Split: Split the full_name and get the third part (age)
# Input: &quot;John_Doe_30&quot;
# Output: &quot;30&quot;
df = df.withColumn(&quot;age&quot;, split(col(&quot;full_name&quot;), &quot;_&quot;)[2])
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="converting-to-other-data-types"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#converting-to-other-data-types"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Converting to Other Data Types</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># 1. Convert string to integer</span>
</span><span class="code-line"><span class="token comment"># Input: "12345"</span>
</span><span class="code-line"><span class="token comment"># Output: 12345 (as an Integer type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"int_parsed"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"int_str"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"int"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 2. Convert string to float</span>
</span><span class="code-line"><span class="token comment"># Input: "123.45"</span>
</span><span class="code-line"><span class="token comment"># Output: 123.45 (as a Float type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"float_parsed"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"int_str"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"float"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 3. Convert string to double</span>
</span><span class="code-line"><span class="token comment"># Input: "123.4567"</span>
</span><span class="code-line"><span class="token comment"># Output: 123.4567 (as a Double type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"double_parsed"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"int_str"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"double"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 4. Convert string to long</span>
</span><span class="code-line"><span class="token comment"># Input: "123456789012"</span>
</span><span class="code-line"><span class="token comment"># Output: 123456789012 (as a Long type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"long_parsed"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"int_str"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"long"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 5. Convert integer to string</span>
</span><span class="code-line"><span class="token comment"># Input: 12345</span>
</span><span class="code-line"><span class="token comment"># Output: "12345" (as a String type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"int_to_str"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"int_parsed"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 6. Convert date to string</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 (Date type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025-01-25" (String type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"date_to_str"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"date_parsed"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># 7. Convert timestamp to string</span>
</span><span class="code-line"><span class="token comment"># Input: 2025-01-25 10:15:00 (Timestamp type)</span>
</span><span class="code-line"><span class="token comment"># Output: "2025-01-25 10:15:00" (String type)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"timestamp_to_str"</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">"timestamp_parsed"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# 1. Convert string to integer
# Input: &quot;12345&quot;
# Output: 12345 (as an Integer type)
df = df.withColumn(&quot;int_parsed&quot;, col(&quot;int_str&quot;).cast(&quot;int&quot;))

# 2. Convert string to float
# Input: &quot;123.45&quot;
# Output: 123.45 (as a Float type)
df = df.withColumn(&quot;float_parsed&quot;, col(&quot;int_str&quot;).cast(&quot;float&quot;))

# 3. Convert string to double
# Input: &quot;123.4567&quot;
# Output: 123.4567 (as a Double type)
df = df.withColumn(&quot;double_parsed&quot;, col(&quot;int_str&quot;).cast(&quot;double&quot;))

# 4. Convert string to long
# Input: &quot;123456789012&quot;
# Output: 123456789012 (as a Long type)
df = df.withColumn(&quot;long_parsed&quot;, col(&quot;int_str&quot;).cast(&quot;long&quot;))

# 5. Convert integer to string
# Input: 12345
# Output: &quot;12345&quot; (as a String type)
df = df.withColumn(&quot;int_to_str&quot;, col(&quot;int_parsed&quot;).cast(&quot;string&quot;))

# 6. Convert date to string
# Input: 2025-01-25 (Date type)
# Output: &quot;2025-01-25&quot; (String type)
df = df.withColumn(&quot;date_to_str&quot;, col(&quot;date_parsed&quot;).cast(&quot;string&quot;))

# 7. Convert timestamp to string
# Input: 2025-01-25 10:15:00 (Timestamp type)
# Output: &quot;2025-01-25 10:15:00&quot; (String type)
df = df.withColumn(&quot;timestamp_to_str&quot;, col(&quot;timestamp_parsed&quot;).cast(&quot;string&quot;))
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<hr>
<h2 id="window-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#window-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Window Functions</h2>
<h3 id="basic-window-functions"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#basic-window-functions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic Window Functions</h3>
<p><strong>Use orderBy()</strong> when order matters:</p>
<ul>
<li>Ranking Functions (row_number, rank, dense_rank)</li>
<li>Offset Functions (lead, lag)</li>
<li>Cumulative Aggregations (sum, avg with rowsBetween)</li>
</ul>
<p><strong>Skip orderBy()</strong> when order is irrelevant:</p>
<ul>
<li>Partition-wise Aggregates (sum, avg, count)</li>
<li>Row-Agnostic Aggregations (max, min)</li>
</ul>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>window <span class="token keyword">import</span> Window
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> col<span class="token punctuation">,</span> row_number<span class="token punctuation">,</span> rank<span class="token punctuation">,</span> dense_rank<span class="token punctuation">,</span> lag<span class="token punctuation">,</span> lead<span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">,</span> avg
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Define window specification (partition by department, order by salary descending)</span>
</span><span class="code-line">window_spec <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>desc<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Apply window functions</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#**row_number:** Assigns unique numbers to each row in a partition.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"row_number"</span><span class="token punctuation">,</span> row_number<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **rank:** Similar to row_number but allows rank gaps.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rank"</span><span class="token punctuation">,</span> rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **dense_rank:** Like rank but without gaps.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"dense_rank"</span><span class="token punctuation">,</span> dense_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **lag:** Gets the previous row's value.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"previous_salary"</span><span class="token punctuation">,</span> lag<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **lead:** Gets the next row's value.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"next_salary"</span><span class="token punctuation">,</span> lead<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **sum:** Computes a running total.</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"running_total"</span><span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># **avg:** Computes a moving average. </span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"moving_avg"</span><span class="token punctuation">,</span> avg<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Show result</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.window import Window
from pyspark.sql.functions import col, row_number, rank, dense_rank, lag, lead, sum, avg

# Define window specification (partition by department, order by salary descending)
window_spec = Window.partitionBy(&quot;department&quot;).orderBy(col(&quot;salary&quot;).desc())

# Apply window functions

#**row_number:** Assigns unique numbers to each row in a partition.
df = df.withColumn(&quot;row_number&quot;, row_number().over(window_spec))

# **rank:** Similar to row_number but allows rank gaps.
df = df.withColumn(&quot;rank&quot;, rank().over(window_spec))

# **dense_rank:** Like rank but without gaps.
df = df.withColumn(&quot;dense_rank&quot;, dense_rank().over(window_spec))

# **lag:** Gets the previous row&#39;s value.
df = df.withColumn(&quot;previous_salary&quot;, lag(&quot;salary&quot;).over(window_spec))

# **lead:** Gets the next row&#39;s value.
df = df.withColumn(&quot;next_salary&quot;, lead(&quot;salary&quot;).over(window_spec))

# **sum:** Computes a running total.
df = df.withColumn(&quot;running_total&quot;, sum(&quot;salary&quot;).over(window_spec))

# **avg:** Computes a moving average. 
df = df.withColumn(&quot;moving_avg&quot;, avg(&quot;salary&quot;).over(window_spec))

# Show result
df.show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="with-rows-between"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-rows-between"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With Rows Between</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>window <span class="token keyword">import</span> Window
</span><span class="code-line"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> col<span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">,</span> avg<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">,</span> count
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#1. Rolling sum over the last 2 rows and current row</span>
</span><span class="code-line">window_spec1 <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rowsBetween<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rolling_sum_last_2"</span><span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec1<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#2. Moving average including previous, current, and next row</span>
</span><span class="code-line">window_spec2 <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rowsBetween<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"moving_avg"</span><span class="token punctuation">,</span> avg<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#3. Rolling minimum for current and next 2 rows</span>
</span><span class="code-line">window_spec3 <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rowsBetween<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rolling_min_next_2"</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec3<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#4. Maximum salary over all previous rows (running max)</span>
</span><span class="code-line">window_spec4 <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rowsBetween<span class="token punctuation">(</span>Window<span class="token punctuation">.</span>unboundedPreceding<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"running_max"</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec4<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#5. Count total rows within the window (entire partition)</span>
</span><span class="code-line">window_spec5 <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"department"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rowsBetween<span class="token punctuation">(</span>Window<span class="token punctuation">.</span>unboundedPreceding<span class="token punctuation">,</span> Window<span class="token punctuation">.</span>unboundedFollowing<span class="token punctuation">)</span>
</span><span class="code-line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"total_rows"</span><span class="token punctuation">,</span> count<span class="token punctuation">(</span><span class="token string">"salary"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>window_spec5<span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Show result</span>
</span><span class="code-line">df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="from pyspark.sql.window import Window
from pyspark.sql.functions import col, sum, avg, min, max, count

#1. Rolling sum over the last 2 rows and current row
window_spec1 = Window.partitionBy(&quot;department&quot;).orderBy(&quot;salary&quot;).rowsBetween(-2, 0)
df = df.withColumn(&quot;rolling_sum_last_2&quot;, sum(&quot;salary&quot;).over(window_spec1))

#2. Moving average including previous, current, and next row
window_spec2 = Window.partitionBy(&quot;department&quot;).orderBy(&quot;salary&quot;).rowsBetween(-1, 1)
df = df.withColumn(&quot;moving_avg&quot;, avg(&quot;salary&quot;).over(window_spec2))

#3. Rolling minimum for current and next 2 rows
window_spec3 = Window.partitionBy(&quot;department&quot;).orderBy(&quot;salary&quot;).rowsBetween(0, 2)
df = df.withColumn(&quot;rolling_min_next_2&quot;, min(&quot;salary&quot;).over(window_spec3))

#4. Maximum salary over all previous rows (running max)
window_spec4 = Window.partitionBy(&quot;department&quot;).orderBy(&quot;salary&quot;).rowsBetween(Window.unboundedPreceding, 0)
df = df.withColumn(&quot;running_max&quot;, max(&quot;salary&quot;).over(window_spec4))

#5. Count total rows within the window (entire partition)
window_spec5 = Window.partitionBy(&quot;department&quot;).orderBy(&quot;salary&quot;).rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)
df = df.withColumn(&quot;total_rows&quot;, count(&quot;salary&quot;).over(window_spec5))

# Show result
df.show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h2 id="running-sql-queries"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#running-sql-queries"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Running SQL Queries</h2>
<h3 id="with-temp-view"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#with-temp-view"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>With Temp View</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Create a temporary SQL table from a DataFrame</span>
</span><span class="code-line">df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"employees"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Select all columns</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM employees"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Select specific columns</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT name, salary FROM employees"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Filter data</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM employees WHERE salary &gt; 50000"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Aggregations</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Sorting</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM employees ORDER BY salary DESC"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Using LIMIT</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT * FROM employees LIMIT 10"</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Using CASE WHEN</span>
</span><span class="code-line">df_sql <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
</span></span><span class="code-line"><span class="token triple-quoted-string string">    SELECT name, salary,
</span></span><span class="code-line"><span class="token triple-quoted-string string">    CASE 
</span></span><span class="code-line"><span class="token triple-quoted-string string">        WHEN salary &gt; 50000 THEN 'High'
</span></span><span class="code-line"><span class="token triple-quoted-string string">        ELSE 'Low'
</span></span><span class="code-line"><span class="token triple-quoted-string string">    END AS salary_category
</span></span><span class="code-line"><span class="token triple-quoted-string string">    FROM employees
</span></span><span class="code-line"><span class="token triple-quoted-string string">"""</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Create a temporary SQL table from a DataFrame
df.createOrReplaceTempView(&quot;employees&quot;)

# Select all columns
df_sql = spark.sql(&quot;SELECT * FROM employees&quot;)

# Select specific columns
df_sql = spark.sql(&quot;SELECT name, salary FROM employees&quot;)

# Filter data
df_sql = spark.sql(&quot;SELECT * FROM employees WHERE salary &gt; 50000&quot;)

# Aggregations
df_sql = spark.sql(&quot;SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department&quot;)

# Sorting
df_sql = spark.sql(&quot;SELECT * FROM employees ORDER BY salary DESC&quot;)

# Using LIMIT
df_sql = spark.sql(&quot;SELECT * FROM employees LIMIT 10&quot;)

# Using CASE WHEN
df_sql = spark.sql(&quot;&quot;&quot;
    SELECT name, salary,
    CASE 
        WHEN salary &gt; 50000 THEN &#39;High&#39;
        ELSE &#39;Low&#39;
    END AS salary_category
    FROM employees
&quot;&quot;&quot;)
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre>
<h3 id="without-temp-view"><a class="anchor" aria-hidden="true" tabindex="-1" href="https://www.sparkplayground.com/pyspark-cheat-sheet#without-temp-view"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Without Temp View</h3>
<pre class="language-python"><code class="language-python code-highlight"><span class="code-line"><span class="token comment"># Load any dataframe</span>
</span><span class="code-line">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">'csv'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">'header'</span><span class="token punctuation">,</span> <span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'/samples/customers.csv'</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># Use Spark SQL with a variable and pass the dataframe</span>
</span><span class="code-line">spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select first_name from {customers_df}"</span><span class="token punctuation">,</span>customers_df <span class="token operator">=</span> df<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Load any dataframe</span>
</span><span class="code-line">df2 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">'csv'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">'header'</span><span class="token punctuation">,</span> <span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'/samples/orders.csv'</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token comment"># Use Spark SQL with a variable and pass the dataframe</span>
</span><span class="code-line">spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select order_id from {orders_df}"</span><span class="token punctuation">,</span>orders_df <span class="token operator">=</span> df2<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code><div class="copied" data-code="# Load any dataframe
df = spark.read.format(&#39;csv&#39;).option(&#39;header&#39;, &#39;true&#39;).load(&#39;/samples/customers.csv&#39;)
# Use Spark SQL with a variable and pass the dataframe
spark.sql(&quot;select first_name from {customers_df}&quot;,customers_df = df).show()

# Load any dataframe
df2 = spark.read.format(&#39;csv&#39;).option(&#39;header&#39;, &#39;true&#39;).load(&#39;/samples/orders.csv&#39;)
# Use Spark SQL with a variable and pass the dataframe
spark.sql(&quot;select order_id from {orders_df}&quot;,orders_df = df2).show()
"><svg class="octicon-copy" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path><path fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path></svg><svg class="octicon-check" aria-hidden="true" viewBox="0 0 16 16" fill="currentColor" height="12" width="12"><path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg></div></pre></div></div></section></main><footer class="bg-base-200 border-t border-base-content/10"><div class="max-w-7xl mx-auto px-8 py-24"><div class=" flex lg:items-start md:flex-row md:flex-nowrap flex-wrap flex-col"><div class="w-64 flex-shrink-0 md:mx-0 mx-auto text-center md:text-left"><a aria-current="page" class="flex gap-2 justify-center md:justify-start items-center" href="https://www.sparkplayground.com/#"><img alt="Spark Playground logo" fetchpriority="high" width="24" height="24" decoding="async" data-nimg="1" class="w-6 h-6" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=32&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ficon.8e0bf7a0.png&amp;w=48&amp;q=75 2x" src="./PySpark Cheat Sheet - Quick Reference Guide_files/icon(1).png" style="color: transparent;"><strong class="font-extrabold tracking-tight text-base md:text-lg">Spark Playground</strong></a><p class="mt-3 text-sm text-base-content/80">Platform to learn, practice, and solve PySpark interview questions to land your next DE role.</p><p class="mt-3 text-sm text-base-content/60">Copyright ¬© 2025 - All rights reserved</p></div><div class="flex-grow flex flex-wrap justify-center -mb-10 md:mt-0 mt-10 text-center"><div class="lg:w-1/3 md:w-1/2 w-full px-4"><div class="footer-title font-semibold text-base-content tracking-widest text-sm md:text-left mb-3">LINKS</div><div class="flex flex-col justify-center items-center md:items-start gap-2 mb-10 text-sm"><a href="mailto:ajulrajar@gmail.com" target="_blank" class="link link-hover" aria-label="Contact Support">Contact Us</a><a class="link link-hover" href="https://www.sparkplayground.com/tutorials">Tutorials</a><a class="link link-hover" href="https://www.sparkplayground.com/pyspark-cheat-sheet">Cheat Sheet</a><a class="link link-hover" href="https://www.sparkplayground.com/pyspark-online-compiler">Online Compiler</a></div></div><div class="lg:w-1/3 md:w-1/2 w-full px-4"><div class="footer-title font-semibold text-base-content tracking-widest text-sm md:text-left mb-3">LEGAL</div><div class="flex flex-col justify-center items-center md:items-start gap-2 mb-10 text-sm"><a class="link link-hover" href="https://www.sparkplayground.com/tos">Terms of Service</a><a class="link link-hover" href="https://www.sparkplayground.com/privacy-policy">Privacy Policy</a></div></div></div></div></div></footer><div style="position: fixed; z-index: 9999; inset: 16px; pointer-events: none;"></div><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/f.txt" id="Absence-banner" async="true" crossorigin="anonymous" data-nscript="afterInteractive"></script><script id="_next-ga-init" data-nscript="afterInteractive">
          window['dataLayer'] = window['dataLayer'] || [];
          function gtag(){window['dataLayer'].push(arguments);}
          gtag('js', new Date());

          gtag('config', 'AW-16685153175');</script><script src="./PySpark Cheat Sheet - Quick Reference Guide_files/js" id="_next-ga" data-nscript="afterInteractive"></script><next-route-announcer style="position: absolute;"><template shadowrootmode="open"><div aria-live="assertive" id="__next-route-announcer__" role="alert" style="position: absolute; border: 0px; height: 1px; margin: -1px; padding: 0px; width: 1px; clip: rect(0px, 0px, 0px, 0px); overflow: hidden; white-space: nowrap; overflow-wrap: normal;">PySpark Cheat Sheet - Quick Reference Guide</div></template></next-route-announcer></body></html>